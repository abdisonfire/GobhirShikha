{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "RFoJDzBXuP4-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations to apply to the data\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# Load the CIFAR dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)"
      ],
      "metadata": {
        "id": "gVKJZwdbzGth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0519a64d-ebc8-494d-eb9e-fecb4779f0c9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(4)\n",
        "train_loader = DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False)"
      ],
      "metadata": {
        "id": "JAOK4Bk0z3pk"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = self.alpha * (1 - pt)**self.gamma * BCE_loss\n",
        "        if self.reduction == 'mean':\n",
        "            return torch.mean(F_loss)\n",
        "        elif self.reduction == 'sum':\n",
        "            return torch.sum(F_loss)\n",
        "        else:\n",
        "            return F_loss"
      ],
      "metadata": {
        "id": "LASLXw4WVWy6"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CifarModel(nn.Module):\n",
        "  def __init__(self, input, hidden_layer1, hidden_layer2, output):\n",
        "        super(CifarModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input, hidden_layer1)\n",
        "        self.fc2 = nn.Linear(hidden_layer1, hidden_layer2)\n",
        "        self.out = nn.Linear(hidden_layer2, output)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = torch.relu(self.fc1(x))\n",
        "      x = torch.relu(self.fc2(x))\n",
        "      x = torch.relu(self.out(x))\n",
        "      return x"
      ],
      "metadata": {
        "id": "4b_3wU543w40"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MlKm_Hiw6kmh"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "cifarModel = CifarModel(3072, 512, 256, 10).to(torch.device('cuda'))\n",
        "\n",
        "criterion = FocalLoss()\n",
        "optimizer = torch.optim.Adam(cifarModel.parameters(), lr=0.00001)\n",
        "\n",
        "losses = []\n",
        "accuracies = []\n",
        "precisions_micro = []\n",
        "recalls_micro = []\n",
        "f1_scores_micro = []\n",
        "precisions_macro = []\n",
        "recalls_macro = []\n",
        "f1_scores_macro = []\n",
        "precisions_weighted = []\n",
        "recalls_weighted = []\n",
        "f1_scores_weighted = []\n",
        "\n",
        "epoch = 100\n",
        "\n",
        "for i in range(epoch):\n",
        "  curr_loss = 0.0\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "\n",
        "  for j, data in enumerate(train_loader):\n",
        "    input, output = data[0].to(torch.device('cuda')), data[1].to(torch.device('cuda'))\n",
        "    input = input.reshape(50, -1)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    pred_out = cifarModel.forward(input)\n",
        "    loss = criterion(pred_out, output)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    curr_loss += loss.item()\n",
        "    y_true += output.tolist()\n",
        "    y_pred += torch.argmax(pred_out, dim=1).tolist()\n",
        "\n",
        "  loss_avg = curr_loss / len(train_loader)\n",
        "  losses.append(loss_avg)\n",
        "\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  accuracies.append(acc*100)\n",
        "\n",
        "  precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_true, y_pred, average='micro', zero_division=1)\n",
        "  precisions_micro.append(precision_micro)\n",
        "  recalls_micro.append(recall_micro)\n",
        "  f1_scores_micro.append(f1_micro)\n",
        "\n",
        "  precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=1)\n",
        "  precisions_macro.append(precision_macro)\n",
        "  recalls_macro.append(recall_macro)\n",
        "  f1_scores_macro.append(f1_macro)\n",
        "\n",
        "  precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=1)\n",
        "  precisions_weighted.append(precision_weighted)\n",
        "  recalls_weighted.append(recall_weighted)\n",
        "  f1_scores_weighted.append(f1_weighted)\n",
        "  print(f'epoch: {i:2}  loss: {loss_avg}')\n",
        "\n",
        "\n",
        "\n",
        "perf_metrics = {\n",
        "    'loss': losses,\n",
        "    'accuracy': accuracies,\n",
        "    'precision_micro': precisions_micro,\n",
        "    'recall_micro': recalls_micro,\n",
        "    'f1_micro': f1_scores_micro,\n",
        "    'precision_macro': precisions_macro,\n",
        "    'recall_macro': recalls_macro,\n",
        "    'f1_macro': f1_scores_macro,\n",
        "    'precision_weighted': precisions_weighted,\n",
        "    'recall_weighted': recalls_weighted,\n",
        "    'f1_weighted': f1_scores_weighted\n",
        "}\n",
        "\n",
        "perf_metrics_df = pd.DataFrame(perf_metrics)\n",
        "display(perf_metrics_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q7lxf57_1wyG",
        "outputId": "2c8d8840-0461-48b6-afd6-f3e5173bed67"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0  loss: 1.700968930363655\n",
            "epoch:  1  loss: 1.555749872803688\n",
            "epoch:  2  loss: 1.5140834943056107\n",
            "epoch:  3  loss: 1.4895096416473388\n",
            "epoch:  4  loss: 1.4512084027528762\n",
            "epoch:  5  loss: 1.4172058469057083\n",
            "epoch:  6  loss: 1.3929166922569274\n",
            "epoch:  7  loss: 1.3721869486570357\n",
            "epoch:  8  loss: 1.3539327210783958\n",
            "epoch:  9  loss: 1.338582332134247\n",
            "epoch: 10  loss: 1.324171062529087\n",
            "epoch: 11  loss: 1.3103296773433686\n",
            "epoch: 12  loss: 1.2975282953977585\n",
            "epoch: 13  loss: 1.2865983999967574\n",
            "epoch: 14  loss: 1.275854957818985\n",
            "epoch: 15  loss: 1.26613978856802\n",
            "epoch: 16  loss: 1.2578339701890946\n",
            "epoch: 17  loss: 1.2496035254597664\n",
            "epoch: 18  loss: 1.2425754835009575\n",
            "epoch: 19  loss: 1.2346082758307457\n",
            "epoch: 20  loss: 1.2282421610951424\n",
            "epoch: 21  loss: 1.2217530051469803\n",
            "epoch: 22  loss: 1.2157480857372285\n",
            "epoch: 23  loss: 1.2095397382378579\n",
            "epoch: 24  loss: 1.2034942786693572\n",
            "epoch: 25  loss: 1.1976610889434816\n",
            "epoch: 26  loss: 1.1921473007798196\n",
            "epoch: 27  loss: 1.1869457440972329\n",
            "epoch: 28  loss: 1.1805506266951562\n",
            "epoch: 29  loss: 1.17612410736084\n",
            "epoch: 30  loss: 1.1708854083418847\n",
            "epoch: 31  loss: 1.1656614911556245\n",
            "epoch: 32  loss: 1.1609490333795547\n",
            "epoch: 33  loss: 1.1561503139734268\n",
            "epoch: 34  loss: 1.1513313551545143\n",
            "epoch: 35  loss: 1.1472858782410622\n",
            "epoch: 36  loss: 1.1426813791394235\n",
            "epoch: 37  loss: 1.138137885093689\n",
            "epoch: 38  loss: 1.1341731483340263\n",
            "epoch: 39  loss: 1.1302698529362678\n",
            "epoch: 40  loss: 1.1259326541423798\n",
            "epoch: 41  loss: 1.1223697020411492\n",
            "epoch: 42  loss: 1.1180820925831794\n",
            "epoch: 43  loss: 1.1142141925096511\n",
            "epoch: 44  loss: 1.110470967233181\n",
            "epoch: 45  loss: 1.1074434891939162\n",
            "epoch: 46  loss: 1.1031430111527443\n",
            "epoch: 47  loss: 1.0997154765725137\n",
            "epoch: 48  loss: 1.0961553170681\n",
            "epoch: 49  loss: 1.0926802262067794\n",
            "epoch: 50  loss: 1.0894432685375213\n",
            "epoch: 51  loss: 1.0864513400793077\n",
            "epoch: 52  loss: 1.0828837658166885\n",
            "epoch: 53  loss: 1.0801224888563157\n",
            "epoch: 54  loss: 1.076680034160614\n",
            "epoch: 55  loss: 1.0731056672930717\n",
            "epoch: 56  loss: 1.069965617597103\n",
            "epoch: 57  loss: 1.066872721850872\n",
            "epoch: 58  loss: 1.0636329753994942\n",
            "epoch: 59  loss: 1.0603747251033784\n",
            "epoch: 60  loss: 1.0574214921593665\n",
            "epoch: 61  loss: 1.0558003259301185\n",
            "epoch: 62  loss: 1.0513937025666238\n",
            "epoch: 63  loss: 1.049079177260399\n",
            "epoch: 64  loss: 1.046101884841919\n",
            "epoch: 65  loss: 1.0432413220405579\n",
            "epoch: 66  loss: 1.0402544558644296\n",
            "epoch: 67  loss: 1.0384123069643973\n",
            "epoch: 68  loss: 1.0359940770864486\n",
            "epoch: 69  loss: 1.0318417593836784\n",
            "epoch: 70  loss: 1.0297296077013016\n",
            "epoch: 71  loss: 1.027056369781494\n",
            "epoch: 72  loss: 1.023911696612835\n",
            "epoch: 73  loss: 1.0218256914019586\n",
            "epoch: 74  loss: 1.0188089997768401\n",
            "epoch: 75  loss: 1.0157739250063895\n",
            "epoch: 76  loss: 1.0133606420755386\n",
            "epoch: 77  loss: 1.0114852724671364\n",
            "epoch: 78  loss: 1.0091301605701446\n",
            "epoch: 79  loss: 1.006266761958599\n",
            "epoch: 80  loss: 1.0031746243834496\n",
            "epoch: 81  loss: 1.0011375950574875\n",
            "epoch: 82  loss: 0.9984853183627128\n",
            "epoch: 83  loss: 0.9964670463204384\n",
            "epoch: 84  loss: 0.9928010158538818\n",
            "epoch: 85  loss: 0.9913735000491142\n",
            "epoch: 86  loss: 0.9889377391934395\n",
            "epoch: 87  loss: 0.9863017526268959\n",
            "epoch: 88  loss: 0.9842163893580437\n",
            "epoch: 89  loss: 0.9810943459868431\n",
            "epoch: 90  loss: 0.9789301078915597\n",
            "epoch: 91  loss: 0.9771767847537994\n",
            "epoch: 92  loss: 0.9740702591538429\n",
            "epoch: 93  loss: 0.9720416911840439\n",
            "epoch: 94  loss: 0.9698787841200829\n",
            "epoch: 95  loss: 0.9673729588389397\n",
            "epoch: 96  loss: 0.9651332088708877\n",
            "epoch: 97  loss: 0.9631209587454795\n",
            "epoch: 98  loss: 0.9604204133152962\n",
            "epoch: 99  loss: 0.9591204056739807\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        loss  accuracy  precision_micro  recall_micro  f1_micro  \\\n",
              "0   1.700969    24.644          0.24644       0.24644   0.24644   \n",
              "1   1.555750    31.396          0.31396       0.31396   0.31396   \n",
              "2   1.514083    33.048          0.33048       0.33048   0.33048   \n",
              "3   1.489510    34.106          0.34106       0.34106   0.34106   \n",
              "4   1.451208    35.430          0.35430       0.35430   0.35430   \n",
              "..       ...       ...              ...           ...       ...   \n",
              "95  0.967373    54.866          0.54866       0.54866   0.54866   \n",
              "96  0.965133    54.974          0.54974       0.54974   0.54974   \n",
              "97  0.963121    55.012          0.55012       0.55012   0.55012   \n",
              "98  0.960420    55.100          0.55100       0.55100   0.55100   \n",
              "99  0.959120    55.138          0.55138       0.55138   0.55138   \n",
              "\n",
              "    precision_macro  recall_macro  f1_macro  precision_weighted  \\\n",
              "0          0.483673       0.24644  0.189247            0.483673   \n",
              "1          0.523794       0.31396  0.259689            0.523794   \n",
              "2          0.536352       0.33048  0.273575            0.536352   \n",
              "3          0.544453       0.34106  0.282365            0.544453   \n",
              "4          0.478967       0.35430  0.308935            0.478967   \n",
              "..              ...           ...       ...                 ...   \n",
              "95         0.646418       0.54866  0.489788            0.646418   \n",
              "96         0.647570       0.54974  0.490855            0.647570   \n",
              "97         0.647873       0.55012  0.491173            0.647873   \n",
              "98         0.648330       0.55100  0.491910            0.648330   \n",
              "99         0.648736       0.55138  0.492200            0.648736   \n",
              "\n",
              "    recall_weighted  f1_weighted  \n",
              "0           0.24644     0.189247  \n",
              "1           0.31396     0.259689  \n",
              "2           0.33048     0.273575  \n",
              "3           0.34106     0.282365  \n",
              "4           0.35430     0.308935  \n",
              "..              ...          ...  \n",
              "95          0.54866     0.489788  \n",
              "96          0.54974     0.490855  \n",
              "97          0.55012     0.491173  \n",
              "98          0.55100     0.491910  \n",
              "99          0.55138     0.492200  \n",
              "\n",
              "[100 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78fb8924-313a-492a-a740-13009be6e6a4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision_micro</th>\n",
              "      <th>recall_micro</th>\n",
              "      <th>f1_micro</th>\n",
              "      <th>precision_macro</th>\n",
              "      <th>recall_macro</th>\n",
              "      <th>f1_macro</th>\n",
              "      <th>precision_weighted</th>\n",
              "      <th>recall_weighted</th>\n",
              "      <th>f1_weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.700969</td>\n",
              "      <td>24.644</td>\n",
              "      <td>0.24644</td>\n",
              "      <td>0.24644</td>\n",
              "      <td>0.24644</td>\n",
              "      <td>0.483673</td>\n",
              "      <td>0.24644</td>\n",
              "      <td>0.189247</td>\n",
              "      <td>0.483673</td>\n",
              "      <td>0.24644</td>\n",
              "      <td>0.189247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.555750</td>\n",
              "      <td>31.396</td>\n",
              "      <td>0.31396</td>\n",
              "      <td>0.31396</td>\n",
              "      <td>0.31396</td>\n",
              "      <td>0.523794</td>\n",
              "      <td>0.31396</td>\n",
              "      <td>0.259689</td>\n",
              "      <td>0.523794</td>\n",
              "      <td>0.31396</td>\n",
              "      <td>0.259689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.514083</td>\n",
              "      <td>33.048</td>\n",
              "      <td>0.33048</td>\n",
              "      <td>0.33048</td>\n",
              "      <td>0.33048</td>\n",
              "      <td>0.536352</td>\n",
              "      <td>0.33048</td>\n",
              "      <td>0.273575</td>\n",
              "      <td>0.536352</td>\n",
              "      <td>0.33048</td>\n",
              "      <td>0.273575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.489510</td>\n",
              "      <td>34.106</td>\n",
              "      <td>0.34106</td>\n",
              "      <td>0.34106</td>\n",
              "      <td>0.34106</td>\n",
              "      <td>0.544453</td>\n",
              "      <td>0.34106</td>\n",
              "      <td>0.282365</td>\n",
              "      <td>0.544453</td>\n",
              "      <td>0.34106</td>\n",
              "      <td>0.282365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.451208</td>\n",
              "      <td>35.430</td>\n",
              "      <td>0.35430</td>\n",
              "      <td>0.35430</td>\n",
              "      <td>0.35430</td>\n",
              "      <td>0.478967</td>\n",
              "      <td>0.35430</td>\n",
              "      <td>0.308935</td>\n",
              "      <td>0.478967</td>\n",
              "      <td>0.35430</td>\n",
              "      <td>0.308935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.967373</td>\n",
              "      <td>54.866</td>\n",
              "      <td>0.54866</td>\n",
              "      <td>0.54866</td>\n",
              "      <td>0.54866</td>\n",
              "      <td>0.646418</td>\n",
              "      <td>0.54866</td>\n",
              "      <td>0.489788</td>\n",
              "      <td>0.646418</td>\n",
              "      <td>0.54866</td>\n",
              "      <td>0.489788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.965133</td>\n",
              "      <td>54.974</td>\n",
              "      <td>0.54974</td>\n",
              "      <td>0.54974</td>\n",
              "      <td>0.54974</td>\n",
              "      <td>0.647570</td>\n",
              "      <td>0.54974</td>\n",
              "      <td>0.490855</td>\n",
              "      <td>0.647570</td>\n",
              "      <td>0.54974</td>\n",
              "      <td>0.490855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.963121</td>\n",
              "      <td>55.012</td>\n",
              "      <td>0.55012</td>\n",
              "      <td>0.55012</td>\n",
              "      <td>0.55012</td>\n",
              "      <td>0.647873</td>\n",
              "      <td>0.55012</td>\n",
              "      <td>0.491173</td>\n",
              "      <td>0.647873</td>\n",
              "      <td>0.55012</td>\n",
              "      <td>0.491173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.960420</td>\n",
              "      <td>55.100</td>\n",
              "      <td>0.55100</td>\n",
              "      <td>0.55100</td>\n",
              "      <td>0.55100</td>\n",
              "      <td>0.648330</td>\n",
              "      <td>0.55100</td>\n",
              "      <td>0.491910</td>\n",
              "      <td>0.648330</td>\n",
              "      <td>0.55100</td>\n",
              "      <td>0.491910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.959120</td>\n",
              "      <td>55.138</td>\n",
              "      <td>0.55138</td>\n",
              "      <td>0.55138</td>\n",
              "      <td>0.55138</td>\n",
              "      <td>0.648736</td>\n",
              "      <td>0.55138</td>\n",
              "      <td>0.492200</td>\n",
              "      <td>0.648736</td>\n",
              "      <td>0.55138</td>\n",
              "      <td>0.492200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78fb8924-313a-492a-a740-13009be6e6a4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-78fb8924-313a-492a-a740-13009be6e6a4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-78fb8924-313a-492a-a740-13009be6e6a4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(epoch), losses, 'b')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "ntwh9xGiUoeQ",
        "outputId": "a3932e37-0e87-4079-d645-b7514dcbbc82"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff26027d070>]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "target_out = []\n",
        "pred_out = []\n",
        "with torch.no_grad():\n",
        "    for (i, data) in enumerate(test_loader):\n",
        "        images, labels = data[0].to(torch.device('cuda')), data[1].to(torch.device('cuda'))\n",
        "        # Predict the class of the image\n",
        "        images = images.reshape(100, -1)\n",
        "        outputs = cifarModel.forward(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        pred_out += predicted.tolist()\n",
        "        target_out += labels.tolist()\n",
        "\n",
        "\n",
        "loss_avg = curr_loss / len(train_loader)\n",
        "\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_true, y_pred, average='micro', zero_division=1)\n",
        "\n",
        "\n",
        "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=1)\n",
        "\n",
        "\n",
        "precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=1)\n",
        "\n",
        "\n",
        "perf_metrics = {\n",
        "    'loss': [loss_avg],\n",
        "    'accuracy': [acc*100],\n",
        "    'precision_micro': [precision_micro*100],\n",
        "    'recall_micro': [recall_micro*100],\n",
        "    'f1_micro': [f1_micro*100],\n",
        "    'precision_macro': [precision_macro*100],\n",
        "    'recall_macro': [recall_macro*100],\n",
        "    'f1_macro': [f1_macro*100],\n",
        "    'precision_weighted': [precision_weighted*100],\n",
        "    'recall_weighted': [recall_weighted*100],\n",
        "    'f1_weighted': [f1_weighted*100]\n",
        "}\n",
        "\n",
        "perf_metrics_df = pd.DataFrame(perf_metrics)\n",
        "display(perf_metrics_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "1tMryjsyQWE2",
        "outputId": "569527bf-40e6-423a-ec4c-1bd61e6593bc"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      loss  accuracy  precision_micro  recall_micro  f1_micro  \\\n",
              "0  0.95912    55.138           55.138        55.138    55.138   \n",
              "\n",
              "   precision_macro  recall_macro   f1_macro  precision_weighted  \\\n",
              "0        44.873603        55.138  49.219981           44.873603   \n",
              "\n",
              "   recall_weighted  f1_weighted  \n",
              "0           55.138    49.219981  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ce00424-da17-4007-ad31-d573adb74768\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision_micro</th>\n",
              "      <th>recall_micro</th>\n",
              "      <th>f1_micro</th>\n",
              "      <th>precision_macro</th>\n",
              "      <th>recall_macro</th>\n",
              "      <th>f1_macro</th>\n",
              "      <th>precision_weighted</th>\n",
              "      <th>recall_weighted</th>\n",
              "      <th>f1_weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.95912</td>\n",
              "      <td>55.138</td>\n",
              "      <td>55.138</td>\n",
              "      <td>55.138</td>\n",
              "      <td>55.138</td>\n",
              "      <td>44.873603</td>\n",
              "      <td>55.138</td>\n",
              "      <td>49.219981</td>\n",
              "      <td>44.873603</td>\n",
              "      <td>55.138</td>\n",
              "      <td>49.219981</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ce00424-da17-4007-ad31-d573adb74768')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ce00424-da17-4007-ad31-d573adb74768 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ce00424-da17-4007-ad31-d573adb74768');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XvhCEt8ScyBS"
      },
      "execution_count": 53,
      "outputs": []
    }
  ]
}