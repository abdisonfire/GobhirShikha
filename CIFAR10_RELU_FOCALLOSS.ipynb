{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "RFoJDzBXuP4-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations to apply to the data\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# Load the CIFAR dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)"
      ],
      "metadata": {
        "id": "gVKJZwdbzGth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03c35f75-2856-4262-c399-2a2f0746b340"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(4)\n",
        "train_loader = DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False)"
      ],
      "metadata": {
        "id": "JAOK4Bk0z3pk"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = self.alpha * (1 - pt)**self.gamma * BCE_loss\n",
        "        if self.reduction == 'mean':\n",
        "            return torch.mean(F_loss)\n",
        "        elif self.reduction == 'sum':\n",
        "            return torch.sum(F_loss)\n",
        "        else:\n",
        "            return F_loss"
      ],
      "metadata": {
        "id": "LASLXw4WVWy6"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CifarModel(nn.Module):\n",
        "  def __init__(self, input, hidden_layer1, hidden_layer2, output):\n",
        "        super(CifarModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input, hidden_layer1)\n",
        "        self.fc2 = nn.Linear(hidden_layer1, hidden_layer2)\n",
        "        self.out = nn.Linear(hidden_layer2, output)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = torch.relu(self.fc1(x))\n",
        "      x = torch.relu(self.fc2(x))\n",
        "      x = torch.relu(self.out(x))\n",
        "      return x"
      ],
      "metadata": {
        "id": "4b_3wU543w40"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MlKm_Hiw6kmh"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "cifarModel = CifarModel(3072, 512, 256, 10).to(torch.device('cuda'))\n",
        "\n",
        "criterion = FocalLoss()\n",
        "optimizer = torch.optim.SGD(cifarModel.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "losses = []\n",
        "accuracies = []\n",
        "precisions_micro = []\n",
        "recalls_micro = []\n",
        "f1_scores_micro = []\n",
        "precisions_macro = []\n",
        "recalls_macro = []\n",
        "f1_scores_macro = []\n",
        "precisions_weighted = []\n",
        "recalls_weighted = []\n",
        "f1_scores_weighted = []\n",
        "\n",
        "epoch = 100\n",
        "\n",
        "for i in range(epoch):\n",
        "  curr_loss = 0.0\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "\n",
        "  for j, data in enumerate(train_loader):\n",
        "    input, output = data[0].to(torch.device('cuda')), data[1].to(torch.device('cuda'))\n",
        "    input = input.reshape(50, -1)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    pred_out = cifarModel.forward(input)\n",
        "    loss = criterion(pred_out, output)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    curr_loss += loss.item()\n",
        "    y_true += output.tolist()\n",
        "    y_pred += torch.argmax(pred_out, dim=1).tolist()\n",
        "\n",
        "  loss_avg = curr_loss / len(train_loader)\n",
        "  losses.append(loss_avg)\n",
        "\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  accuracies.append(acc*100)\n",
        "\n",
        "  precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_true, y_pred, average='micro', zero_division=1)\n",
        "  precisions_micro.append(precision_micro)\n",
        "  recalls_micro.append(recall_micro)\n",
        "  f1_scores_micro.append(f1_micro)\n",
        "\n",
        "  precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=1)\n",
        "  precisions_macro.append(precision_macro)\n",
        "  recalls_macro.append(recall_macro)\n",
        "  f1_scores_macro.append(f1_macro)\n",
        "\n",
        "  precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=1)\n",
        "  precisions_weighted.append(precision_weighted)\n",
        "  recalls_weighted.append(recall_weighted)\n",
        "  f1_scores_weighted.append(f1_weighted)\n",
        "  print(f'epoch: {i:2}  loss: {loss_avg}')\n",
        "\n",
        "\n",
        "\n",
        "perf_metrics = {\n",
        "    'loss': losses,\n",
        "    'accuracy': accuracies,\n",
        "    'precision_micro': precisions_micro,\n",
        "    'recall_micro': recalls_micro,\n",
        "    'f1_micro': f1_scores_micro,\n",
        "    'precision_macro': precisions_macro,\n",
        "    'recall_macro': recalls_macro,\n",
        "    'f1_macro': f1_scores_macro,\n",
        "    'precision_weighted': precisions_weighted,\n",
        "    'recall_weighted': recalls_weighted,\n",
        "    'f1_weighted': f1_scores_weighted\n",
        "}\n",
        "\n",
        "perf_metrics_df = pd.DataFrame(perf_metrics)\n",
        "display(perf_metrics_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q7lxf57_1wyG",
        "outputId": "2b5d8f4f-4267-4b8f-8801-155d8a746e8c"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0  loss: 1.4658070210814476\n",
            "epoch:  1  loss: 1.2044433211088181\n",
            "epoch:  2  loss: 1.1192858953475953\n",
            "epoch:  3  loss: 1.059104755461216\n",
            "epoch:  4  loss: 1.0125483709573746\n",
            "epoch:  5  loss: 0.9847948623895645\n",
            "epoch:  6  loss: 0.950278680562973\n",
            "epoch:  7  loss: 0.9261342034339904\n",
            "epoch:  8  loss: 0.8965807240605355\n",
            "epoch:  9  loss: 0.8719925097823144\n",
            "epoch: 10  loss: 0.8500361394286156\n",
            "epoch: 11  loss: 0.8260210618078708\n",
            "epoch: 12  loss: 0.804844992518425\n",
            "epoch: 13  loss: 0.7832600736320019\n",
            "epoch: 14  loss: 0.7638385422825813\n",
            "epoch: 15  loss: 0.7484611283242703\n",
            "epoch: 16  loss: 0.7400434395670891\n",
            "epoch: 17  loss: 0.7176164557337761\n",
            "epoch: 18  loss: 0.7016793635487556\n",
            "epoch: 19  loss: 0.6819396876096725\n",
            "epoch: 20  loss: 0.6660139093101025\n",
            "epoch: 21  loss: 0.6584163549244404\n",
            "epoch: 22  loss: 0.6467202595174313\n",
            "epoch: 23  loss: 0.6281032477617263\n",
            "epoch: 24  loss: 0.617585739850998\n",
            "epoch: 25  loss: 0.5998836268484592\n",
            "epoch: 26  loss: 0.5869440545886755\n",
            "epoch: 27  loss: 0.5723935806006193\n",
            "epoch: 28  loss: 0.5642720297276974\n",
            "epoch: 29  loss: 0.5536426303833724\n",
            "epoch: 30  loss: 0.5368109836280346\n",
            "epoch: 31  loss: 0.527492382735014\n",
            "epoch: 32  loss: 0.5164829398542643\n",
            "epoch: 33  loss: 0.5079294473528863\n",
            "epoch: 34  loss: 0.49333777107298377\n",
            "epoch: 35  loss: 0.4801765522956848\n",
            "epoch: 36  loss: 0.47523976883292196\n",
            "epoch: 37  loss: 0.46084715954959393\n",
            "epoch: 38  loss: 0.4558978667706251\n",
            "epoch: 39  loss: 0.44606666040420534\n",
            "epoch: 40  loss: 0.42773555366694926\n",
            "epoch: 41  loss: 0.4204750121831894\n",
            "epoch: 42  loss: 0.408270132496953\n",
            "epoch: 43  loss: 0.41379875580966474\n",
            "epoch: 44  loss: 0.39609691597521307\n",
            "epoch: 45  loss: 0.384625344581902\n",
            "epoch: 46  loss: 0.3886310468018055\n",
            "epoch: 47  loss: 0.37850773361325263\n",
            "epoch: 48  loss: 0.3667937204763293\n",
            "epoch: 49  loss: 0.3664155423641205\n",
            "epoch: 50  loss: 0.3437645369321108\n",
            "epoch: 51  loss: 0.3478522157520056\n",
            "epoch: 52  loss: 0.3409480465427041\n",
            "epoch: 53  loss: 0.3267345645800233\n",
            "epoch: 54  loss: 0.31918774390220644\n",
            "epoch: 55  loss: 0.3184133313372731\n",
            "epoch: 56  loss: 0.3123306416869164\n",
            "epoch: 57  loss: 0.312240125387907\n",
            "epoch: 58  loss: 0.2998181518912315\n",
            "epoch: 59  loss: 0.2896157647743821\n",
            "epoch: 60  loss: 0.28837730933725836\n",
            "epoch: 61  loss: 0.2779982318840921\n",
            "epoch: 62  loss: 0.2772140702456236\n",
            "epoch: 63  loss: 0.2711359686665237\n",
            "epoch: 64  loss: 0.26676539677381517\n",
            "epoch: 65  loss: 0.2659834289774299\n",
            "epoch: 66  loss: 0.25239569290727376\n",
            "epoch: 67  loss: 0.24556539994105697\n",
            "epoch: 68  loss: 0.2542540602311492\n",
            "epoch: 69  loss: 0.2421988705508411\n",
            "epoch: 70  loss: 0.24014554829895496\n",
            "epoch: 71  loss: 0.22854016674309968\n",
            "epoch: 72  loss: 0.23262548096105456\n",
            "epoch: 73  loss: 0.23341623781993986\n",
            "epoch: 74  loss: 0.21840770648419858\n",
            "epoch: 75  loss: 0.2124664702564478\n",
            "epoch: 76  loss: 0.2138892346806824\n",
            "epoch: 77  loss: 0.19376160226389766\n",
            "epoch: 78  loss: 0.19792229479551315\n",
            "epoch: 79  loss: 0.20428959137946368\n",
            "epoch: 80  loss: 0.2006964592952281\n",
            "epoch: 81  loss: 0.19883398853614925\n",
            "epoch: 82  loss: 0.19281426574103533\n",
            "epoch: 83  loss: 0.17628995905071496\n",
            "epoch: 84  loss: 0.1909686251282692\n",
            "epoch: 85  loss: 0.192453736577183\n",
            "epoch: 86  loss: 0.1857358855959028\n",
            "epoch: 87  loss: 0.18787808403745293\n",
            "epoch: 88  loss: 0.16539522000402213\n",
            "epoch: 89  loss: 0.1807042985614389\n",
            "epoch: 90  loss: 0.17976053949818016\n",
            "epoch: 91  loss: 0.1765461361128837\n",
            "epoch: 92  loss: 0.14994994168169795\n",
            "epoch: 93  loss: 0.16177349068969488\n",
            "epoch: 94  loss: 0.15556316207535564\n",
            "epoch: 95  loss: 0.15595533588714897\n",
            "epoch: 96  loss: 0.1512762565240264\n",
            "epoch: 97  loss: 0.15729339007101953\n",
            "epoch: 98  loss: 0.14988323375955223\n",
            "epoch: 99  loss: 0.14597740449011326\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        loss  accuracy  precision_micro  recall_micro  f1_micro  \\\n",
              "0   1.465807    30.262          0.30262       0.30262   0.30262   \n",
              "1   1.204443    38.716          0.38716       0.38716   0.38716   \n",
              "2   1.119286    41.918          0.41918       0.41918   0.41918   \n",
              "3   1.059105    44.024          0.44024       0.44024   0.44024   \n",
              "4   1.012548    45.966          0.45966       0.45966   0.45966   \n",
              "..       ...       ...              ...           ...       ...   \n",
              "95  0.155955    87.300          0.87300       0.87300   0.87300   \n",
              "96  0.151276    87.492          0.87492       0.87492   0.87492   \n",
              "97  0.157293    87.244          0.87244       0.87244   0.87244   \n",
              "98  0.149883    87.566          0.87566       0.87566   0.87566   \n",
              "99  0.145977    87.928          0.87928       0.87928   0.87928   \n",
              "\n",
              "    precision_macro  recall_macro  f1_macro  precision_weighted  \\\n",
              "0          0.293990       0.30262  0.288843            0.293990   \n",
              "1          0.382417       0.38716  0.382774            0.382417   \n",
              "2          0.414815       0.41918  0.415095            0.414815   \n",
              "3          0.435844       0.44024  0.436110            0.435844   \n",
              "4          0.455903       0.45966  0.456142            0.455903   \n",
              "..              ...           ...       ...                 ...   \n",
              "95         0.873070       0.87300  0.873025            0.873070   \n",
              "96         0.874980       0.87492  0.874943            0.874980   \n",
              "97         0.872455       0.87244  0.872436            0.872455   \n",
              "98         0.875685       0.87566  0.875662            0.875685   \n",
              "99         0.879338       0.87928  0.879298            0.879338   \n",
              "\n",
              "    recall_weighted  f1_weighted  \n",
              "0           0.30262     0.288843  \n",
              "1           0.38716     0.382774  \n",
              "2           0.41918     0.415095  \n",
              "3           0.44024     0.436110  \n",
              "4           0.45966     0.456142  \n",
              "..              ...          ...  \n",
              "95          0.87300     0.873025  \n",
              "96          0.87492     0.874943  \n",
              "97          0.87244     0.872436  \n",
              "98          0.87566     0.875662  \n",
              "99          0.87928     0.879298  \n",
              "\n",
              "[100 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b11c7703-ddd7-47a2-8c98-95de658c87bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision_micro</th>\n",
              "      <th>recall_micro</th>\n",
              "      <th>f1_micro</th>\n",
              "      <th>precision_macro</th>\n",
              "      <th>recall_macro</th>\n",
              "      <th>f1_macro</th>\n",
              "      <th>precision_weighted</th>\n",
              "      <th>recall_weighted</th>\n",
              "      <th>f1_weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.465807</td>\n",
              "      <td>30.262</td>\n",
              "      <td>0.30262</td>\n",
              "      <td>0.30262</td>\n",
              "      <td>0.30262</td>\n",
              "      <td>0.293990</td>\n",
              "      <td>0.30262</td>\n",
              "      <td>0.288843</td>\n",
              "      <td>0.293990</td>\n",
              "      <td>0.30262</td>\n",
              "      <td>0.288843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.204443</td>\n",
              "      <td>38.716</td>\n",
              "      <td>0.38716</td>\n",
              "      <td>0.38716</td>\n",
              "      <td>0.38716</td>\n",
              "      <td>0.382417</td>\n",
              "      <td>0.38716</td>\n",
              "      <td>0.382774</td>\n",
              "      <td>0.382417</td>\n",
              "      <td>0.38716</td>\n",
              "      <td>0.382774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.119286</td>\n",
              "      <td>41.918</td>\n",
              "      <td>0.41918</td>\n",
              "      <td>0.41918</td>\n",
              "      <td>0.41918</td>\n",
              "      <td>0.414815</td>\n",
              "      <td>0.41918</td>\n",
              "      <td>0.415095</td>\n",
              "      <td>0.414815</td>\n",
              "      <td>0.41918</td>\n",
              "      <td>0.415095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.059105</td>\n",
              "      <td>44.024</td>\n",
              "      <td>0.44024</td>\n",
              "      <td>0.44024</td>\n",
              "      <td>0.44024</td>\n",
              "      <td>0.435844</td>\n",
              "      <td>0.44024</td>\n",
              "      <td>0.436110</td>\n",
              "      <td>0.435844</td>\n",
              "      <td>0.44024</td>\n",
              "      <td>0.436110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.012548</td>\n",
              "      <td>45.966</td>\n",
              "      <td>0.45966</td>\n",
              "      <td>0.45966</td>\n",
              "      <td>0.45966</td>\n",
              "      <td>0.455903</td>\n",
              "      <td>0.45966</td>\n",
              "      <td>0.456142</td>\n",
              "      <td>0.455903</td>\n",
              "      <td>0.45966</td>\n",
              "      <td>0.456142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.155955</td>\n",
              "      <td>87.300</td>\n",
              "      <td>0.87300</td>\n",
              "      <td>0.87300</td>\n",
              "      <td>0.87300</td>\n",
              "      <td>0.873070</td>\n",
              "      <td>0.87300</td>\n",
              "      <td>0.873025</td>\n",
              "      <td>0.873070</td>\n",
              "      <td>0.87300</td>\n",
              "      <td>0.873025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.151276</td>\n",
              "      <td>87.492</td>\n",
              "      <td>0.87492</td>\n",
              "      <td>0.87492</td>\n",
              "      <td>0.87492</td>\n",
              "      <td>0.874980</td>\n",
              "      <td>0.87492</td>\n",
              "      <td>0.874943</td>\n",
              "      <td>0.874980</td>\n",
              "      <td>0.87492</td>\n",
              "      <td>0.874943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.157293</td>\n",
              "      <td>87.244</td>\n",
              "      <td>0.87244</td>\n",
              "      <td>0.87244</td>\n",
              "      <td>0.87244</td>\n",
              "      <td>0.872455</td>\n",
              "      <td>0.87244</td>\n",
              "      <td>0.872436</td>\n",
              "      <td>0.872455</td>\n",
              "      <td>0.87244</td>\n",
              "      <td>0.872436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.149883</td>\n",
              "      <td>87.566</td>\n",
              "      <td>0.87566</td>\n",
              "      <td>0.87566</td>\n",
              "      <td>0.87566</td>\n",
              "      <td>0.875685</td>\n",
              "      <td>0.87566</td>\n",
              "      <td>0.875662</td>\n",
              "      <td>0.875685</td>\n",
              "      <td>0.87566</td>\n",
              "      <td>0.875662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.145977</td>\n",
              "      <td>87.928</td>\n",
              "      <td>0.87928</td>\n",
              "      <td>0.87928</td>\n",
              "      <td>0.87928</td>\n",
              "      <td>0.879338</td>\n",
              "      <td>0.87928</td>\n",
              "      <td>0.879298</td>\n",
              "      <td>0.879338</td>\n",
              "      <td>0.87928</td>\n",
              "      <td>0.879298</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b11c7703-ddd7-47a2-8c98-95de658c87bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b11c7703-ddd7-47a2-8c98-95de658c87bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b11c7703-ddd7-47a2-8c98-95de658c87bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(epoch), losses, 'b')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "ntwh9xGiUoeQ",
        "outputId": "36c772b0-d6b0-46a8-b527-8d873580da59"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd5e04035b0>]"
            ]
          },
          "metadata": {},
          "execution_count": 195
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "target_out = []\n",
        "pred_out = []\n",
        "with torch.no_grad():\n",
        "    for (i, data) in enumerate(test_loader):\n",
        "        images, labels = data[0].to(torch.device('cuda')), data[1].to(torch.device('cuda'))\n",
        "        # Predict the class of the image\n",
        "        images = images.reshape(100, -1)\n",
        "        outputs = cifarModel.forward(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        pred_out += predicted.tolist()\n",
        "        target_out += labels.tolist()\n",
        "\n",
        "\n",
        "loss_avg = curr_loss / len(train_loader)\n",
        "\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
        "\n",
        "\n",
        "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
        "\n",
        "\n",
        "precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "perf_metrics = {\n",
        "    'loss': [loss_avg],\n",
        "    'accuracy': [acc*100],\n",
        "    'precision_micro': [precision_micro*100],\n",
        "    'recall_micro': [recall_micro*100],\n",
        "    'f1_micro': [f1_micro*100],\n",
        "    'precision_macro': [precision_macro*100],\n",
        "    'recall_macro': [recall_macro*100],\n",
        "    'f1_macro': [f1_macro*100],\n",
        "    'precision_weighted': [precision_weighted*100],\n",
        "    'recall_weighted': [recall_weighted*100],\n",
        "    'f1_weighted': [f1_weighted*100]\n",
        "}\n",
        "\n",
        "perf_metrics_df = pd.DataFrame(perf_metrics)\n",
        "display(perf_metrics_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "1tMryjsyQWE2",
        "outputId": "4b6d1f00-dfc5-4836-fc88-c7a13f2e1b33"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       loss  accuracy  precision_micro  recall_micro  f1_micro  \\\n",
              "0  0.145977    87.928           87.928        87.928    87.928   \n",
              "\n",
              "   precision_macro  recall_macro   f1_macro  precision_weighted  \\\n",
              "0        87.933807        87.928  87.929839           87.933807   \n",
              "\n",
              "   recall_weighted  f1_weighted  \n",
              "0           87.928    87.929839  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b1675ad-8722-4bfc-828a-1171ed9230ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision_micro</th>\n",
              "      <th>recall_micro</th>\n",
              "      <th>f1_micro</th>\n",
              "      <th>precision_macro</th>\n",
              "      <th>recall_macro</th>\n",
              "      <th>f1_macro</th>\n",
              "      <th>precision_weighted</th>\n",
              "      <th>recall_weighted</th>\n",
              "      <th>f1_weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.145977</td>\n",
              "      <td>87.928</td>\n",
              "      <td>87.928</td>\n",
              "      <td>87.928</td>\n",
              "      <td>87.928</td>\n",
              "      <td>87.933807</td>\n",
              "      <td>87.928</td>\n",
              "      <td>87.929839</td>\n",
              "      <td>87.933807</td>\n",
              "      <td>87.928</td>\n",
              "      <td>87.929839</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b1675ad-8722-4bfc-828a-1171ed9230ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b1675ad-8722-4bfc-828a-1171ed9230ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b1675ad-8722-4bfc-828a-1171ed9230ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XvhCEt8ScyBS"
      },
      "execution_count": 196,
      "outputs": []
    }
  ]
}