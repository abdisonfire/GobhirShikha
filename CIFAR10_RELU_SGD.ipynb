{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "RFoJDzBXuP4-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations to apply to the data\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# Load the CIFAR dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)"
      ],
      "metadata": {
        "id": "gVKJZwdbzGth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8301a876-e536-4696-c133-623d98b775a6"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(4)\n",
        "train_loader = DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False)"
      ],
      "metadata": {
        "id": "JAOK4Bk0z3pk"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CifarModel(nn.Module):\n",
        "  def __init__(self, input, hidden_layer1, hidden_layer2, output):\n",
        "        super(CifarModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input, hidden_layer1)\n",
        "        self.fc2 = nn.Linear(hidden_layer1, hidden_layer2)\n",
        "        self.out = nn.Linear(hidden_layer2, output)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = torch.relu(self.fc1(x))\n",
        "      x = torch.relu(self.fc2(x))\n",
        "      x = torch.relu(self.out(x))\n",
        "      return x"
      ],
      "metadata": {
        "id": "4b_3wU543w40"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MlKm_Hiw6kmh"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "cifarModel = CifarModel(3072, 512, 256, 10).to(torch.device('cuda'))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(cifarModel.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "losses = []\n",
        "accuracies = []\n",
        "precisions_micro = []\n",
        "recalls_micro = []\n",
        "f1_scores_micro = []\n",
        "precisions_macro = []\n",
        "recalls_macro = []\n",
        "f1_scores_macro = []\n",
        "precisions_weighted = []\n",
        "recalls_weighted = []\n",
        "f1_scores_weighted = []\n",
        "\n",
        "for i in range(100):\n",
        "  curr_loss = 0.0\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "\n",
        "  for j, data in enumerate(train_loader):\n",
        "    input, output = data[0].to(torch.device('cuda')), data[1].to(torch.device('cuda'))\n",
        "    input = input.reshape(50, -1)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    pred_out = cifarModel.forward(input)\n",
        "    loss = criterion(pred_out, output)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    curr_loss += loss.item()\n",
        "    y_true += output.tolist()\n",
        "    y_pred += torch.argmax(pred_out, dim=1).tolist()\n",
        "\n",
        "  loss_avg = curr_loss / len(train_loader)\n",
        "  losses.append(loss_avg)\n",
        "\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  accuracies.append(acc*100)\n",
        "\n",
        "  precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_true, y_pred, average='micro', zero_division=1)\n",
        "  precisions_micro.append(precision_micro)\n",
        "  recalls_micro.append(recall_micro)\n",
        "  f1_scores_micro.append(f1_micro)\n",
        "\n",
        "  precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=1)\n",
        "  precisions_macro.append(precision_macro)\n",
        "  recalls_macro.append(recall_macro)\n",
        "  f1_scores_macro.append(f1_macro)\n",
        "\n",
        "  precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=1)\n",
        "  precisions_weighted.append(precision_weighted)\n",
        "  recalls_weighted.append(recall_weighted)\n",
        "  f1_scores_weighted.append(f1_weighted)\n",
        "  print(f'epoch: {i:2}  loss: {loss_avg}')\n",
        "\n",
        "\n",
        "\n",
        "perf_metrics = {\n",
        "    'loss': losses,\n",
        "    'accuracy': accuracies,\n",
        "    'precision_micro': precisions_micro,\n",
        "    'recall_micro': recalls_micro,\n",
        "    'f1_micro': f1_scores_micro,\n",
        "    'precision_macro': precisions_macro,\n",
        "    'recall_macro': recalls_macro,\n",
        "    'f1_macro': f1_scores_macro,\n",
        "    'precision_weighted': precisions_weighted,\n",
        "    'recall_weighted': recalls_weighted,\n",
        "    'f1_weighted': f1_scores_weighted\n",
        "}\n",
        "\n",
        "perf_metrics_df = pd.DataFrame(perf_metrics)\n",
        "display(perf_metrics_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q7lxf57_1wyG",
        "outputId": "02ed2f0e-9c75-45c8-f667-5dc31b7883a8"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0  loss: 1.9411037157773972\n",
            "epoch:  1  loss: 1.6992553470134735\n",
            "epoch:  2  loss: 1.6080958948135375\n",
            "epoch:  3  loss: 1.5398295118808747\n",
            "epoch:  4  loss: 1.493722913622856\n",
            "epoch:  5  loss: 1.4583230097293853\n",
            "epoch:  6  loss: 1.4178673183321953\n",
            "epoch:  7  loss: 1.3892077880501748\n",
            "epoch:  8  loss: 1.3633478891849518\n",
            "epoch:  9  loss: 1.33056716889143\n",
            "epoch: 10  loss: 1.3008196394443512\n",
            "epoch: 11  loss: 1.2753267621994018\n",
            "epoch: 12  loss: 1.250175263106823\n",
            "epoch: 13  loss: 1.2276900847554206\n",
            "epoch: 14  loss: 1.2028342683911324\n",
            "epoch: 15  loss: 1.1838441882133484\n",
            "epoch: 16  loss: 1.168102617442608\n",
            "epoch: 17  loss: 1.142533313691616\n",
            "epoch: 18  loss: 1.118462883591652\n",
            "epoch: 19  loss: 1.103161338865757\n",
            "epoch: 20  loss: 1.0836413183212281\n",
            "epoch: 21  loss: 1.0599277301430703\n",
            "epoch: 22  loss: 1.0458474835753442\n",
            "epoch: 23  loss: 1.0222559056282043\n",
            "epoch: 24  loss: 1.0101941774487495\n",
            "epoch: 25  loss: 0.9924643750190735\n",
            "epoch: 26  loss: 0.9693678372502327\n",
            "epoch: 27  loss: 0.961532564342022\n",
            "epoch: 28  loss: 0.9305631830096245\n",
            "epoch: 29  loss: 0.9198957938551903\n",
            "epoch: 30  loss: 0.911532526999712\n",
            "epoch: 31  loss: 0.888728625357151\n",
            "epoch: 32  loss: 0.8723762866854667\n",
            "epoch: 33  loss: 0.8639913903474807\n",
            "epoch: 34  loss: 0.8451216642260552\n",
            "epoch: 35  loss: 0.8317001880705357\n",
            "epoch: 36  loss: 0.8114257044196129\n",
            "epoch: 37  loss: 0.8091975250840187\n",
            "epoch: 38  loss: 0.7871533545851708\n",
            "epoch: 39  loss: 0.7693552763164043\n",
            "epoch: 40  loss: 0.7542210373282433\n",
            "epoch: 41  loss: 0.7505650904774666\n",
            "epoch: 42  loss: 0.7245252342224121\n",
            "epoch: 43  loss: 0.7271361293196679\n",
            "epoch: 44  loss: 0.7037298330664634\n",
            "epoch: 45  loss: 0.6990362468063831\n",
            "epoch: 46  loss: 0.677139455229044\n",
            "epoch: 47  loss: 0.6662769378721713\n",
            "epoch: 48  loss: 0.6445508119910955\n",
            "epoch: 49  loss: 0.6517137435376644\n",
            "epoch: 50  loss: 0.6475683930516243\n",
            "epoch: 51  loss: 0.6258418347239494\n",
            "epoch: 52  loss: 0.621359115421772\n",
            "epoch: 53  loss: 0.6099275560230016\n",
            "epoch: 54  loss: 0.6007474611401558\n",
            "epoch: 55  loss: 0.5810515869855881\n",
            "epoch: 56  loss: 0.56933563567698\n",
            "epoch: 57  loss: 0.5651018934696913\n",
            "epoch: 58  loss: 0.5630503325611353\n",
            "epoch: 59  loss: 0.5336887195855379\n",
            "epoch: 60  loss: 0.5465210221707821\n",
            "epoch: 61  loss: 0.5359103754758835\n",
            "epoch: 62  loss: 0.5288126194626093\n",
            "epoch: 63  loss: 0.5094826886802912\n",
            "epoch: 64  loss: 0.5138050667643547\n",
            "epoch: 65  loss: 0.5020427901893855\n",
            "epoch: 66  loss: 0.500245112195611\n",
            "epoch: 67  loss: 0.47137311343848703\n",
            "epoch: 68  loss: 0.49415423181653023\n",
            "epoch: 69  loss: 0.468294760003686\n",
            "epoch: 70  loss: 0.461406131580472\n",
            "epoch: 71  loss: 0.4555780820697546\n",
            "epoch: 72  loss: 0.4567287087589502\n",
            "epoch: 73  loss: 0.44684424693882463\n",
            "epoch: 74  loss: 0.43748446048796175\n",
            "epoch: 75  loss: 0.44462334878742693\n",
            "epoch: 76  loss: 0.42394146882742645\n",
            "epoch: 77  loss: 0.44240399384498597\n",
            "epoch: 78  loss: 0.42192531254142523\n",
            "epoch: 79  loss: 0.4214260329529643\n",
            "epoch: 80  loss: 0.4014421726614237\n",
            "epoch: 81  loss: 0.3986446646675467\n",
            "epoch: 82  loss: 0.3875284702628851\n",
            "epoch: 83  loss: 0.38959571428596973\n",
            "epoch: 84  loss: 0.40071050719916823\n",
            "epoch: 85  loss: 0.39155103828758003\n",
            "epoch: 86  loss: 0.3974785489216447\n",
            "epoch: 87  loss: 0.3814394418299198\n",
            "epoch: 88  loss: 0.36242475832253696\n",
            "epoch: 89  loss: 0.3801912958547473\n",
            "epoch: 90  loss: 0.36153956258296965\n",
            "epoch: 91  loss: 0.36924620666354896\n",
            "epoch: 92  loss: 0.376170000910759\n",
            "epoch: 93  loss: 0.357487812563777\n",
            "epoch: 94  loss: 0.3622717229798436\n",
            "epoch: 95  loss: 0.3704776846319437\n",
            "epoch: 96  loss: 0.31706673999503254\n",
            "epoch: 97  loss: 0.3531474425308406\n",
            "epoch: 98  loss: 0.36230607871711257\n",
            "epoch: 99  loss: 0.32812888560444115\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        loss  accuracy  precision_micro  recall_micro  f1_micro  \\\n",
              "0   1.941104    30.104          0.30104       0.30104   0.30104   \n",
              "1   1.699255    39.086          0.39086       0.39086   0.39086   \n",
              "2   1.608096    42.594          0.42594       0.42594   0.42594   \n",
              "3   1.539830    44.850          0.44850       0.44850   0.44850   \n",
              "4   1.493723    46.586          0.46586       0.46586   0.46586   \n",
              "..       ...       ...              ...           ...       ...   \n",
              "95  0.370478    87.094          0.87094       0.87094   0.87094   \n",
              "96  0.317067    89.016          0.89016       0.89016   0.89016   \n",
              "97  0.353147    87.662          0.87662       0.87662   0.87662   \n",
              "98  0.362306    87.410          0.87410       0.87410   0.87410   \n",
              "99  0.328129    88.550          0.88550       0.88550   0.88550   \n",
              "\n",
              "    precision_macro  recall_macro  f1_macro  precision_weighted  \\\n",
              "0          0.292993       0.30104  0.286962            0.292993   \n",
              "1          0.384948       0.39086  0.385329            0.384948   \n",
              "2          0.419975       0.42594  0.420458            0.419975   \n",
              "3          0.442604       0.44850  0.443234            0.442604   \n",
              "4          0.460454       0.46586  0.460781            0.460454   \n",
              "..              ...           ...       ...                 ...   \n",
              "95         0.871006       0.87094  0.870941            0.871006   \n",
              "96         0.890223       0.89016  0.890171            0.890223   \n",
              "97         0.876674       0.87662  0.876628            0.876674   \n",
              "98         0.874189       0.87410  0.874126            0.874189   \n",
              "99         0.885615       0.88550  0.885536            0.885615   \n",
              "\n",
              "    recall_weighted  f1_weighted  \n",
              "0           0.30104     0.286962  \n",
              "1           0.39086     0.385329  \n",
              "2           0.42594     0.420458  \n",
              "3           0.44850     0.443234  \n",
              "4           0.46586     0.460781  \n",
              "..              ...          ...  \n",
              "95          0.87094     0.870941  \n",
              "96          0.89016     0.890171  \n",
              "97          0.87662     0.876628  \n",
              "98          0.87410     0.874126  \n",
              "99          0.88550     0.885536  \n",
              "\n",
              "[100 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-261c8f4a-d73d-4499-8c5e-926fdfabcbdf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision_micro</th>\n",
              "      <th>recall_micro</th>\n",
              "      <th>f1_micro</th>\n",
              "      <th>precision_macro</th>\n",
              "      <th>recall_macro</th>\n",
              "      <th>f1_macro</th>\n",
              "      <th>precision_weighted</th>\n",
              "      <th>recall_weighted</th>\n",
              "      <th>f1_weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.941104</td>\n",
              "      <td>30.104</td>\n",
              "      <td>0.30104</td>\n",
              "      <td>0.30104</td>\n",
              "      <td>0.30104</td>\n",
              "      <td>0.292993</td>\n",
              "      <td>0.30104</td>\n",
              "      <td>0.286962</td>\n",
              "      <td>0.292993</td>\n",
              "      <td>0.30104</td>\n",
              "      <td>0.286962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.699255</td>\n",
              "      <td>39.086</td>\n",
              "      <td>0.39086</td>\n",
              "      <td>0.39086</td>\n",
              "      <td>0.39086</td>\n",
              "      <td>0.384948</td>\n",
              "      <td>0.39086</td>\n",
              "      <td>0.385329</td>\n",
              "      <td>0.384948</td>\n",
              "      <td>0.39086</td>\n",
              "      <td>0.385329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.608096</td>\n",
              "      <td>42.594</td>\n",
              "      <td>0.42594</td>\n",
              "      <td>0.42594</td>\n",
              "      <td>0.42594</td>\n",
              "      <td>0.419975</td>\n",
              "      <td>0.42594</td>\n",
              "      <td>0.420458</td>\n",
              "      <td>0.419975</td>\n",
              "      <td>0.42594</td>\n",
              "      <td>0.420458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.539830</td>\n",
              "      <td>44.850</td>\n",
              "      <td>0.44850</td>\n",
              "      <td>0.44850</td>\n",
              "      <td>0.44850</td>\n",
              "      <td>0.442604</td>\n",
              "      <td>0.44850</td>\n",
              "      <td>0.443234</td>\n",
              "      <td>0.442604</td>\n",
              "      <td>0.44850</td>\n",
              "      <td>0.443234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.493723</td>\n",
              "      <td>46.586</td>\n",
              "      <td>0.46586</td>\n",
              "      <td>0.46586</td>\n",
              "      <td>0.46586</td>\n",
              "      <td>0.460454</td>\n",
              "      <td>0.46586</td>\n",
              "      <td>0.460781</td>\n",
              "      <td>0.460454</td>\n",
              "      <td>0.46586</td>\n",
              "      <td>0.460781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.370478</td>\n",
              "      <td>87.094</td>\n",
              "      <td>0.87094</td>\n",
              "      <td>0.87094</td>\n",
              "      <td>0.87094</td>\n",
              "      <td>0.871006</td>\n",
              "      <td>0.87094</td>\n",
              "      <td>0.870941</td>\n",
              "      <td>0.871006</td>\n",
              "      <td>0.87094</td>\n",
              "      <td>0.870941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.317067</td>\n",
              "      <td>89.016</td>\n",
              "      <td>0.89016</td>\n",
              "      <td>0.89016</td>\n",
              "      <td>0.89016</td>\n",
              "      <td>0.890223</td>\n",
              "      <td>0.89016</td>\n",
              "      <td>0.890171</td>\n",
              "      <td>0.890223</td>\n",
              "      <td>0.89016</td>\n",
              "      <td>0.890171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.353147</td>\n",
              "      <td>87.662</td>\n",
              "      <td>0.87662</td>\n",
              "      <td>0.87662</td>\n",
              "      <td>0.87662</td>\n",
              "      <td>0.876674</td>\n",
              "      <td>0.87662</td>\n",
              "      <td>0.876628</td>\n",
              "      <td>0.876674</td>\n",
              "      <td>0.87662</td>\n",
              "      <td>0.876628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.362306</td>\n",
              "      <td>87.410</td>\n",
              "      <td>0.87410</td>\n",
              "      <td>0.87410</td>\n",
              "      <td>0.87410</td>\n",
              "      <td>0.874189</td>\n",
              "      <td>0.87410</td>\n",
              "      <td>0.874126</td>\n",
              "      <td>0.874189</td>\n",
              "      <td>0.87410</td>\n",
              "      <td>0.874126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.328129</td>\n",
              "      <td>88.550</td>\n",
              "      <td>0.88550</td>\n",
              "      <td>0.88550</td>\n",
              "      <td>0.88550</td>\n",
              "      <td>0.885615</td>\n",
              "      <td>0.88550</td>\n",
              "      <td>0.885536</td>\n",
              "      <td>0.885615</td>\n",
              "      <td>0.88550</td>\n",
              "      <td>0.885536</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-261c8f4a-d73d-4499-8c5e-926fdfabcbdf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-261c8f4a-d73d-4499-8c5e-926fdfabcbdf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-261c8f4a-d73d-4499-8c5e-926fdfabcbdf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(100), losses, 'b')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "ntwh9xGiUoeQ",
        "outputId": "f49005cb-3888-44d1-d177-884824d04de1"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd5e59d1490>]"
            ]
          },
          "metadata": {},
          "execution_count": 179
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD6CAYAAACxrrxPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAg40lEQVR4nO3deXhU5dnH8e/NqiggSlwI0CACFVckgryiolDZqqioBfetSBVrq21d2rpUxeVVq62KF1WKVYsLouJSlyqIC1qDBURARZFNLEFUsKgBud8/7vElYBImZMLJzPw+15UrOTMnM/dx8MfhOc+5H3N3REQk+9VLugAREckMBbqISI5QoIuI5AgFuohIjlCgi4jkCAW6iEiO2GSgm1kbM5tkZrPN7B0zO7+CfczM/mRm88xsppntVzvliohIZRqksc9a4EJ3f8vMmgLTzOx5d59dbp/+QIfUV3dgVOp7pVq2bOlFRUWbV7WISJ6aNm3acncvqOi5TQa6uy8FlqZ+XmVmc4BCoHygDwL+5nGX0utmtp2Z7ZL63QoVFRVRUlJSneMQEcl7ZragsueqNYZuZkVAF+CNjZ4qBBaV216cekxERLaQtAPdzLYFHgF+4e4rN+fNzGyYmZWYWUlpaenmvISIiFQirUA3s4ZEmN/v7hMq2GUJ0KbcduvUYxtw99HuXuzuxQUFFQ4BiYjIZkpnlosBdwNz3P3mSnabCJySmu1yAPBFVePnIiKSeenMcjkQOBl428ympx67FGgL4O53Ak8DA4B5wGrg9IxXKiIiVUpnlssrgG1iHwfOzVRRIiJSfbpTVEQkR2RdoL/9Nlx6KaxYkXQlIiJ1S9YF+gcfwLXXwvz5SVciIlK3ZF2gF6ZuV1ryvUmRIiL5LesCvVWr+P7xx8nWISJS12RdoO+0E9SrpzN0EZGNZV2gN2gAO++sQBcR2VjWBTrEOLqGXERENpSVgd6qlc7QRUQ2lpWBXlioQBcR2VjWBvpnn8FXXyVdiYhI3ZG1gQ4aRxcRKS8rA/27uegadhERWS8rA113i4qIfF9WB7qGXERE1svKQG/WDJo00Rm6iEh56SxBN8bMlpnZrEqeb25mT5jZDDN7x8xqfbUiM01dFBHZWDpn6GOBflU8fy4w2933AXoBN5lZo5qXVjUFuojIhjYZ6O4+BahqOQkHmqYWk942te/azJRXOd3+LyKyoUyMod8G7A58DLwNnO/u6yra0cyGmVmJmZWUlpbW6E1btYpAd6/Ry4iI5IxMBHpfYDrQCtgXuM3MmlW0o7uPdvdidy8uKCio0ZsWFsI338Cnn9boZUREckYmAv10YIKHecB84IcZeN0qaS66iMiGMhHoC4HeAGa2E9AJ+DADr1slzUUXEdlQg03tYGbjiNkrLc1sMXA50BDA3e8ErgLGmtnbgAEXufvyWqs4Rbf/i4hsaJOB7u5DN/H8x8DhGasoTbvsEt8V6CIiISvvFAVo1Ah23FFDLiIi38naQAfdXCQiUl5WB7qWohMRWS+rA11n6CIi62V9oJeWQllZ0pWIiCQv6wMdYOnSZOsQEakLciLQP/oo0TJEROqErA70/feP3uiTJyddiYhI8rI60HfYIUL92WeTrkREJHlZHegAffvCG2/AZ58lXYmISLJyItDXrYMXXki6EhGRZGV9oHfrFotGa9hFRPJd1gd6w4bQu3cEulYvEpF8lvWBDjHssmgRzJ2bdCUiIsnJmUAHDbuISH7bZKCb2RgzW2Zms6rYp5eZTTezd8zspcyWuGlFRdCxowJdRPJbOmfoY4F+lT1pZtsBdwBHuvsewHEZqaya+vaFl16Cr79O4t1FRJK3yUB39ynAiip2OYFYJHphav9lGaqtWvr2ha++ilAXEclHmRhD7wi0MLPJZjbNzE7JwGtWW+/e0Lw53H9/Eu8uIpK8TAR6A6ArMBDoC/zezDpWtKOZDTOzEjMrKS0tzcBbr7fVVnD88fDII7BqVUZfWkQkK2Qi0BcDz7r7f919OTAF2KeiHd19tLsXu3txQUFBBt56Q6eeCqtXw4QJGX9pEZE6LxOB/jjQ08wamFkToDswJwOvW23/8z+w225wzz1JvLuISLLSmbY4DpgKdDKzxWZ2ppkNN7PhAO4+B3gGmAn8C7jL3Sud4libzOCUU2DSJFiwIIkKRESSY57Q/fLFxcVeUlKS8df96CNo1w6uugp+97uMv7yISKLMbJq7F1f0XE7cKVpeUREccgj87W/q7SIi+SXnAh3i4uj778PUqUlXIiKy5eRkoB97LGy/PVx5ZdKViIhsOTkZ6E2bxvj5c8/Fl4hIPsjJQAc455y4OPqb38SKRiIiuS5nA71xYxg5EmbMgPvuS7oaEZHal7OBDtEKoLg4hl+++irpakREaldOB3q9enDDDbGa0XXXJV2NiEjtyulABzj0UDj5ZLj6anjttaSrERGpPTkf6AC33QY/+AGceCKsXJl0NSIitSMvAr1Zs+iTvmgRnHtu0tWIiNSOvAh0gB494LLLYsbLAw8kXY2ISOblTaADXHopdO8OP/85rKhqUT0RkSyUV4HeoAGMHh1hftFFSVcjIpJZeRXoAHvvDRdcAHfdBS+/nHQ1IiKZk84CF2PMbJmZVblohZntb2ZrzezYzJVXOy6/PGa9nH02lJUlXY2ISGakc4Y+FuhX1Q5mVh+4HsiKVljbbAO33w5z5sAf/pB0NSIimbHJQHf3KcCmLiGeBzwCLMtEUVvCwIFw+ulwzTVag1REckODmr6AmRUCRwOHAvvXuKIt6M47YeFCOOssaNUKfvSjpCsSEdl8mbgoegtwkbtvskmtmQ0zsxIzKyktLc3AW9dMo0bwyCPQuTMMHhydGUVEslUmAr0YeMDMPgKOBe4ws6Mq2tHdR7t7sbsXFxQUZOCta655c3j66fh++OEwd27SFYmIbJ4aB7q7t3P3IncvAsYD57j7YzV93S2psBD++U8wg8MOi/VIRUSyTTrTFscBU4FOZrbYzM40s+FmNrz2y9tyOnWCF1+EtWsj1D/8MOmKRESqx9w9kTcuLi72kpKSRN67KjNnRsvdHXaAN9+MoRgRkbrCzKa5e3FFz+XdnaKbsvfe8PjjcYZ+xhmQ0N93IiLVpkCvQM+esdLRhAlw881JVyMikh4FeiV++cuYynjRRer5IiLZQYFeCTMYMwZ23RWOOw4WLEi6IhGRqinQq9CsWYynf/01HHGElq8TkbpNgb4Ju+8O48fD7NkwZEhMaxQRqYsU6Gno0wfuuAP+8Q84/3zNfBGRuqnGzbnyxbBhcQfpjTdG+93rr49xdhGRukKBXg033ACrV8P//i/Urw8jRyrURaTuUKBXgxncdhusWwfXXQf16sHVVyvURaRuUKBXk1msdrRuXZyhg0JdROoGBfpmqFcPRo2KEB85Mi6SXnONQl1EkqVA30z16sXMFzO49toIdY2pi0iSFOg1UK9eDL+YxZj6p59GyDfQf1URSYCip4a+C/Xtt49hl6VL4YEHYmqjiMiWpBuLMsAsLoyOGhXL2R12GKxYkXRVIpJv0lmxaIyZLTOzWZU8f6KZzTSzt83sNTPbJ/NlZofhw6Pl7owZ0Lt3DMGIiGwp6ZyhjwX6VfH8fOAQd98LuAoYnYG6stagQdHQa86cOFMvLU26IhHJF5sMdHefAlQ6gODur7n7Z6nN14HWGaota/XtC08+Ga0CDj0UPvoo6YpEJB9kegz9TOAflT1pZsPMrMTMSkpz/NS1Tx946ilYtAi6dIGJE5OuSERyXcYC3cwOJQL9osr2cffR7l7s7sUFBQWZeus669BD4a23YpGMQYPgV7+Cb75JuioRyVUZCXQz2xu4Cxjk7roUWE779vDaazBiBNx0E+yzD7z0UtJViUguqnGgm1lbYAJwsru/V/OSck/jxvDnP0c/9bIy6NULTj9dKyCJSGalM21xHDAV6GRmi83sTDMbbmbDU7tcBuwA3GFm082spBbrzWr9+sGsWXDJJXDvvXHxVKEuIplintDyO8XFxV5Skr/Z/+ijcPzx0K0bPPMMNG2adEUikg3MbJq7F1f0nO4UTcjRR0eLgDfegAED4Msvk65IRLKdAj1BgwfDuHEwdWoMv3z+edIViUg2U6An7Ljj4MEH4c03487S5cuTrkhEspUCvQ4YPHh9u4BDDombkUREqkuBXkf07x/TGhcuhM6dY876mjVJVyUi2USBXof06hWdGg85JO4q7dIlLpqKiKRDgV7H7LorPPEEPPYYrFoFBx0Et90WS9yJiFRFgV4HmUXvl+nT42ak886DE0/U1EYRqZoCvQ5r0SLO1EeOjJkwhxyi/uoiUjkFeh1Xr160CnjiCZg9Gw4+GBYvTroqEamLFOhZYsAAeO45+Phj6NkT3lMbNBHZiAI9ixx0EEyaBP/9b7Th/e1v48KpiAgo0LPOfvvBtGnRC2bkSNhtN7j//qSrEpG6QIGehdq2hb//Peaot28PJ50E11+fdFUikjQFehbr1i1WPxo6FC6+OC6ear66SP5KZ4GLMWa2zMxmVfK8mdmfzGyemc00s/0yX6ZUpmHDWCxj+HC47jo4+eRoHyAi+SedM/SxQL8qnu8PdEh9DQNG1bwsqY769eGOO+Dyy2O+evv2cMYZmgkjkm82GejuPgVYUcUug4C/eXgd2M7MdslUgZIeM7jiCvjgAzjnnFg8Y6+94MYbYd26pKsTkS0hE2PohUD5hq+LU49JAtq2hVtvhfnz4cc/hl//Gnr31jCMSD7YohdFzWyYmZWYWUmp7mGvVTvtBOPHw5gxUFIC++4Lr76adFUiUpsyEehLgDbltlunHvsedx/t7sXuXlxQUJCBt5aqmMHpp8O//w0tW0KfPvDUU0lXJSK1JROBPhE4JTXb5QDgC3dfmoHXlQzZbTd45RXYY4/o4jhmjMbVRXJROtMWxwFTgU5mttjMzjSz4WY2PLXL08CHwDzgL8A5tVatbLYdd4y2Ab16wZlnQmEhDBsGzz+vuesiucI8of+bi4uLvaSkJJH3zmdlZTG2/thjseTdl1/C7bfHzBgRqfvMbJq7F1f0nO4UzTONGsEJJ8BDD8Hy5TET5vzzYfLkpCsTkZpSoOexxo3hvvtijP3YY2Oqo4hkLwV6nmveHCZOhG+/jQumc+cmXZGIbC4FutChQ7QMeP992H13OPxwePxxWLMm6cpEpDoU6AJEiC9YANdcA3PmwFFHwc47x4yYZ57RNEeRbKBAl/+3445w6aUxlv7449C/Pzz8cHw/7jj4+uukKxSRqijQ5XsaNIAjj4wLpqWlcMMNMGEC9OsHn3+edHUiUhkFulSpceNo8DVuHLz2Ghx8sBp9idRVCnRJy5Ah8PTTMRyz554wapTG1UXqGgW6pK1PH5g5E7p3jztLe/WKHjEKdpG6QYEu1dKuHTz3XDT4evttOOggaNMGfv5zePfdpKsTyW8KdKm279ryLlwI998fi1WPHg1dusDYsUlXJ5K/FOiy2Zo2jb4wjz4aY+sHHBBBf+qp0fRLRLYsBbpkxC67RCveyy+He++NO07HjIG1a5OuTCR/KNAlY+rXj4Wqp0yBVq3iLtO99oo2vSJS+9IKdDPrZ2bvmtk8M7u4gufbmtkkM/u3mc00swGZL1WyRc+e8PrrcTMSwIABEfSaDSNSu9JZsag+cDvQH+gMDDWzzhvt9jvgIXfvAgwB7sh0oZJdzODoo+Gtt2JM/corY3vlyqQrE8ld6ZyhdwPmufuH7l4GPAAM2mgfB5qlfm4OfJy5EiWbbb01/PWv8Kc/xQLVLVtC69bQtWvMZV+9OukKRXJHgzT2KQQWldteDHTfaJ8rgOfM7DxgG6BPRqqTnGAG550H++8fM2KWLYOlS+HOO2HaNHjiiWgMJiI1k06gp2MoMNbdbzKzHsC9Zranu28wampmw4BhAG3bts3QW0u2OOCA+PrOo4/GtMcePeLCaceOydUmkgvSGXJZArQpt9069Vh5ZwIPAbj7VGAroOXGL+Tuo9292N2LCwoKNq9iyRlHHx1rma5aFe0EHnoo6YpEsls6gf4m0MHM2plZI+Ki58SN9lkI9AYws92JQC/NZKGSm7p3jxkxnTrBT34SF1B14VRk82wy0N19LTACeBaYQ8xmecfM/mBmR6Z2uxD4qZnNAMYBp7m711bRklt23RVefhkuuyx6sO+9d4yri0j1WFK5W1xc7CUlJYm8t9RdU6fCWWfB7NkwcCDceiu0b590VSJ1h5lNc/fiip7TnaJSp/ToAdOnw403wksvwW67xTTHXr2io+OKFUlXKFJ3KdClzmnYEC68MNrxjhwZfdjXrIlpjocfDl98kXSFInVTpqYtimRcq1ZwySXrt594Ao45JhatfvbZ6PYoIusp0CVrHHEEPPggHH98LFjdsyd8/HGcsf/mN7Etks8U6JJVjjkmZsKcdhqUlMRZ/FdfwY9+BOPHx4VUkXylMXTJOkOGxFn511/Hwhpvvw177AFHHRUrKInkKwW6ZKXGjaNHDEBBAbz4Ygy5nHRSrHN63nlw993w2WfJ1imyJSnQJSc0axb9YC6+GNzhnntiPnu3bvD++0lXJ7JlKNAlZ2y1FVx7LbzyCnz+OUyaFN979IBXX026OpHap0CXnFSvXtyM9PrrsP320Ls33HBDBLxIrlKgS05r3z7aCfTqBRddBIWFsbDGRx8lXZlI5inQJeftsAM880wsh/eTn8CYMbFi0pQpSVcmklkKdMkbXbpEmM+eHSsk9ekTc9rdYe5cuOWWWMz6wQdjKmRZWdIVi1SPbiySvLPrrvDaa3GT0sknx8yYJaklW8wi4AHatoWJE2GffZKrVaQ6dIYuealFi+gHc+GFsdbpqFFxk9Lq1TBjBtx7L3z7bcxtf+aZpKsVSY/6oYtUYsmS6B8zYwZceWX0j+ncGZo0SboyyWc17oduZv3M7F0zm2dmF1eyz/FmNtvM3jGzv9ekYJG6oLAwLpwOHAi//32cyTdtCvvuC6NHRw8Zkbpkk4FuZvWB24H+QGdgqJl13mifDsAlwIHuvgfwi8yXKrLlbbstPP44vPcePPJIBHv9+nD22fCDH8RF1AULkq5SJKRzht4NmOfuH7p7GfAAMGijfX4K3O7unwG4+7LMlimSHDPo0CEuol5xRXR5nDQp2gpceSUUFcEhh8Bf/xrj7iJJSSfQC4FF5bYXpx4rryPQ0cxeNbPXzaxfRS9kZsPMrMTMSkpLSzevYpGEmcWNSk8+GRdSr74a/vMfOOMMGDAAli9PukLJV5ma5dIA6AD0AoYCfzGz7Tbeyd1Hu3uxuxcXFBRk6K1FklNUBL/9LcyZA3/5S6yD2rVrnMWLbGnpBPoSoE257dapx8pbDEx09zXuPh94jwh4kbxgFt0dX3kltg88MFoMfPhhsnVJfkkn0N8EOphZOzNrBAwBJm60z2PE2Tlm1pIYgtEfZck7xcXRYuCUU6Ife4cOsWTe6NHR8VH92aU2bTLQ3X0tMAJ4FpgDPOTu75jZH8zsyNRuzwKfmtlsYBLwa3f/tLaKFqnLdtghhl/mz4df/Qqefz5mxfTsGZ0fmzSJu1C7dYOnnkq6WsklurFIpJatWwcLF8I778RY+yefQGlptPZdtAgmT45wF0lHVTcWqZeLSC2rVy8unhYVbbiI9bJlcMABcTfqG2/E87Nnw003xQ1MP/sZdOqUUNGSldTLRSQhO+4YQy5lZTHd8YQTYM89o9vjHXfAD38Ihx8Of/+7pkJKehToIgnafXd49FGYNy/uSL3oorjzdNGimN8+ezaceGKEf/fucOed67tBimxMY+gidcCcOdCyJWx8e8a338K0adHxceLE+PmYY6Kve/PmydQqyapqDF2BLpIl3OHmm+Msvl27uKFp/nyYNSvG6UeMgIMPjjnxkrsU6CI55JVXYim9jz+OIN9tN1ixIsbZu3eH4cOhTZuYItm2bUyjlNxR4/a5IlJ39OwZQzQzZsB//wvvvhvTIm+/PWbOnH56LK+3337QunW0Iyjvm2/g6adh7dpk6pfao0AXyULNmsHee8NWW8X21ltHq4H33oshmJdeggkTYmjmqKPi4irAF1/EQh0DB8bye+oOmVs0D10khzRoAHvssX67S5eY6z5gQAT86adHuA8ZAg88AA0bRtvf+vWTq1kyR4EuksOKimKu+8EHRxfIbbaJ7cMPj+X0LrsMGjWCW2+N5yS7achFJMd17Qrjx8eZ+uTJEeYQqy/97nfRRGz77aF3b7j+epg6NcbZJftolotIHnOP1ZeefjqaiM2cGY83bhx/ETRpAl9+CatXR7+Zs86K75oamRxNWxSRtPznP9Hm99VX4V//isZi224bY/OTJ0ew77lnrM50wgmw007xe2Vl0WyssBDat9/wNd1hzZoY2pGaU6CLSI2tXBl9Zu66K8K+fn3o3z/C/p//jDP5rbaKIZwTTojfmT8/fp4/PxbZPvDAZI8hF2geuojUWLNm8NOfRmfId96JXu8zZsD06XDSSfDwwzEcc+KJcPHFMYtm331jzvw228Chh0afeKk9aZ2hpxZ9vhWoD9zl7tdVst9gYDywv7tXefqtM3SR3FNWBuefH03EAHr0iG6R220HQ4dGT5pBg+JO1oYN4/u552o4pjpqNORiZvWJNUJ/RKwd+iYw1N1nb7RfU+ApoBEwQoEukr/Gjo3x+AsuiOCGuInp97+Pee9lZTGuvmpVDMM8/DDsskuiJWeNmg65dAPmufuH7l4GPAAMqmC/q4Drga83u1IRyQmnnRZNxL4Lc4gx95EjYelS+PTT9WPy06dHm4KXXoqLsLL50gn0QmBRue3Fqcf+n5ntB7Rxd62QKCJpO/74mB2z7bbQq1dcVC0qijnx99xT8Xz4efPgvPNi7vxBB8UC3J99Fs3KHnooxvYffTQ/+8anM+RyLNDP3c9KbZ8MdHf3EantesCLwGnu/pGZTQZ+VdGQi5kNA4YBtG3btuuCBQsyeSwikqU+/zzO1r9b3KOkBObOhZ13jimSjRrFOqzvvx/z5Rs0iB41s2bFRdf69df3palXL870jzwyGpa1bp3kkWVeTcfQewBXuHvf1PYlAO5+bWq7OfAB8GXqV3YGVgBHVjWOrjF0EamMewT3LbfAP/4Rj7VoEQF/7LHRiGznnWO/t96KPjUtW0Ynyr32gttui7YGDRrEGq1nnbXhzVDPPgtffRV/KWSbqgIdd6/yi+j38iHQjrjgOQPYo4r9JwPFm3rdrl27uojIpqxc6V5WVv3f++AD99693cF96NB4nVWr3M86Kx4D99NOc//yy/W/s2qV+8SJ7iNGuHfs6N6qVWxXZvly9xdfdF+3rvr1bS6gxCvJ1U0253L3tWY2AniWmLY4xt3fMbM/pF54Yo3/yhERqUTTppv3e7vuCs89B9deG2fr06bFUMwHH8All8TZ+9VXxxj+2WfHvwheeCHG7Zs0iTH9JUti6OaXv4Trrouz/Dlz4k7aCROibcK338J998X8+4p88w28/HL00tl2283+z5AW3SkqIjlv8uSYB9+4Mdx7b1xMBXjxxQjiTz6JvwAGDYIf/zimUjZuHGH861/Dn/8cQzwrVsSUS4COHWHw4LgA26BB3GRVr9w0kzffjLVfH3wwLtoOHAhPPFHzPji69V9E8t7q1XHxtHHjDR9fuTJWemrfvvKwfeyxmHXToUPc/dq1awS6WfwFccopsYj3EUfE/s89B337xsIjRx8dPW/++McYz7/ggpodhwJdRKSWrFkTQd+qVQzFrFgRF2a32y5aETdvHiP2gwfHGfqrr0aLhM2lXi4iIrWkYcMYlpk6FaZMiUW6ly+H+++PMIc4k7/77uhGOWRILAVYGxToIiI1dMYZsOOO0Vly/Hi46qpY/q+8Fi1g3LhY0PuSS2qnDgW6iEgNbb01/OIXcbfqQQfF3aoV6dEjLpJeeWXt1KE1RUVEMmDEiOgJ/7OfVb3o9uDBtVeDAl1EJAOaNoVrrkm2Bg25iIjkCAW6iEiOUKCLiOQIBbqISI5QoIuI5AgFuohIjlCgi4jkCAW6iEiOSKzbopmVApu7qGhLYHkGy8kW+Xjc+XjMkJ/HnY/HDNU/7h+4e0FFTyQW6DVhZiWVtY/MZfl43Pl4zJCfx52PxwyZPW4NuYiI5AgFuohIjsjWQB+ddAEJycfjzsdjhvw87nw8ZsjgcWflGLqIiHxftp6hi4jIRrIu0M2sn5m9a2bzzOzipOupDWbWxswmmdlsM3vHzM5PPb69mT1vZu+nvrdIutbaYGb1zezfZvZkarudmb2R+swfNLNGSdeYSWa2nZmNN7O5ZjbHzHrkw2dtZr9M/fmeZWbjzGyrXPyszWyMmS0zs1nlHqvw87Xwp9TxzzSz/arzXlkV6GZWH7gd6A90BoaaWedkq6oVa4EL3b0zcABwbuo4LwZecPcOwAup7Vx0PjCn3Pb1wB/dfTfgM+DMRKqqPbcCz7j7D4F9iGPP6c/azAqBnwPF7r4nUB8YQm5+1mOBfhs9Vtnn2x/okPoaBoyqzhtlVaAD3YB57v6hu5cBDwCDEq4p49x9qbu/lfp5FfE/eCFxrPekdrsHOCqRAmuRmbUGBgJ3pbYNOAwYn9olp47bzJoDBwN3A7h7mbt/Th581sSKaVubWQOgCbCUHPys3X0KsGKjhyv7fAcBf/PwOrCdme2S7ntlW6AXAovKbS9OPZazzKwI6AK8Aezk7ktTT30C7JRUXbXoFuA3wLrU9g7A5+6+NrWda595O6AU+GtqmOkuM9uGHP+s3X0JcCOwkAjyL4Bp5PZnXV5ln2+NMi7bAj2vmNm2wCPAL9x9ZfnnPKYn5dQUJTP7MbDM3aclXcsW1ADYDxjl7l2A/7LR8EqOftYtiLPRdkArYBu+PyyRFzL5+WZboC8B2pTbbp16LOeYWUMizO939wmph//z3T+/Ut+XJVVfLTkQONLMPiKG0w4jxpe3S/2zHHLvM18MLHb3N1Lb44mAz/XPug8w391L3X0NMIH4/HP5sy6vss+3RhmXbYH+JtAhdSW8EXERZWLCNWVcatz4bmCOu99c7qmJwKmpn08FHt/StdUmd7/E3Vu7exHx2b7o7icCk4BjU7vl1HG7+yfAIjPrlHqoNzCbHP+siaGWA8ysSerP+3fHnbOf9UYq+3wnAqekZrscAHxRbmhm09w9q76AAcB7wAfAb5Oup5aOsSfxT7CZwPTU1wBiPPkF4H3gn8D2Sddai/8NegFPpn7eFfgXMA94GGicdH0ZPtZ9gZLU5/0Y0CIfPmvgSmAuMAu4F2ici581MI64TrCG+BfZmZV9voARM/k+AN4mZgGl/V66U1REJEdk25CLiIhUQoEuIpIjFOgiIjlCgS4ikiMU6CIiOUKBLiKSIxToIiI5QoEuIpIj/g+c2nMQoLOFGAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "target_out = []\n",
        "pred_out = []\n",
        "with torch.no_grad():\n",
        "    for (i, data) in enumerate(test_loader):\n",
        "        images, labels = data[0].to(torch.device('cuda')), data[1].to(torch.device('cuda'))\n",
        "        # Predict the class of the image\n",
        "        images = images.reshape(100, -1)\n",
        "        outputs = cifarModel.forward(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        pred_out += predicted.tolist()\n",
        "        target_out += labels.tolist()\n",
        "\n",
        "\n",
        "loss_avg = curr_loss / len(train_loader)\n",
        "\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
        "\n",
        "\n",
        "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
        "\n",
        "\n",
        "precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "perf_metrics = {\n",
        "    'loss': [loss_avg],\n",
        "    'accuracy': [acc*100],\n",
        "    'precision_micro': [precision_micro*100],\n",
        "    'recall_micro': [recall_micro*100],\n",
        "    'f1_micro': [f1_micro*100],\n",
        "    'precision_macro': [precision_macro*100],\n",
        "    'recall_macro': [recall_macro*100],\n",
        "    'f1_macro': [f1_macro*100],\n",
        "    'precision_weighted': [precision_weighted*100],\n",
        "    'recall_weighted': [recall_weighted*100],\n",
        "    'f1_weighted': [f1_weighted*100]\n",
        "}\n",
        "\n",
        "perf_metrics_df = pd.DataFrame(perf_metrics)\n",
        "display(perf_metrics_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "1tMryjsyQWE2",
        "outputId": "a51a1882-412e-4f39-81fa-d17ddd388035"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       loss  accuracy  precision_micro  recall_micro  f1_micro  \\\n",
              "0  0.328129     88.55            88.55         88.55     88.55   \n",
              "\n",
              "   precision_macro  recall_macro  f1_macro  precision_weighted  \\\n",
              "0        88.561514         88.55  88.55355           88.561514   \n",
              "\n",
              "   recall_weighted  f1_weighted  \n",
              "0            88.55     88.55355  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eae5cde2-f295-46b9-bf09-58d32b85d7b3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision_micro</th>\n",
              "      <th>recall_micro</th>\n",
              "      <th>f1_micro</th>\n",
              "      <th>precision_macro</th>\n",
              "      <th>recall_macro</th>\n",
              "      <th>f1_macro</th>\n",
              "      <th>precision_weighted</th>\n",
              "      <th>recall_weighted</th>\n",
              "      <th>f1_weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.328129</td>\n",
              "      <td>88.55</td>\n",
              "      <td>88.55</td>\n",
              "      <td>88.55</td>\n",
              "      <td>88.55</td>\n",
              "      <td>88.561514</td>\n",
              "      <td>88.55</td>\n",
              "      <td>88.55355</td>\n",
              "      <td>88.561514</td>\n",
              "      <td>88.55</td>\n",
              "      <td>88.55355</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eae5cde2-f295-46b9-bf09-58d32b85d7b3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eae5cde2-f295-46b9-bf09-58d32b85d7b3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eae5cde2-f295-46b9-bf09-58d32b85d7b3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XvhCEt8ScyBS"
      },
      "execution_count": 176,
      "outputs": []
    }
  ]
}