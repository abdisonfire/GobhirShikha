{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RFoJDzBXuP4-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations to apply to the data\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# Load the CIFAR dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)"
      ],
      "metadata": {
        "id": "gVKJZwdbzGth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be48c8ae-aa6b-4306-df14-2d5bf23ad22c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(4)\n",
        "train_loader = DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False)"
      ],
      "metadata": {
        "id": "JAOK4Bk0z3pk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = self.alpha * (1 - pt)**self.gamma * BCE_loss\n",
        "        if self.reduction == 'mean':\n",
        "            return torch.mean(F_loss)\n",
        "        elif self.reduction == 'sum':\n",
        "            return torch.sum(F_loss)\n",
        "        else:\n",
        "            return F_loss"
      ],
      "metadata": {
        "id": "LASLXw4WVWy6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CifarModel(nn.Module):\n",
        "  def __init__(self, input, hidden_layer1, hidden_layer2, output):\n",
        "        super(CifarModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input, hidden_layer1)\n",
        "        self.fc2 = nn.Linear(hidden_layer1, hidden_layer2)\n",
        "        self.out = nn.Linear(hidden_layer2, output)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = torch.relu(self.fc1(x))\n",
        "      x = torch.relu(self.fc2(x))\n",
        "      x = torch.relu(self.out(x))\n",
        "      return x"
      ],
      "metadata": {
        "id": "4b_3wU543w40"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MlKm_Hiw6kmh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "cifarModel = CifarModel(3072, 512, 256, 10).to(torch.device('cuda'))\n",
        "\n",
        "criterion = FocalLoss()\n",
        "optimizer = torch.optim.Adam(cifarModel.parameters(), lr=0.0001)\n",
        "\n",
        "losses = []\n",
        "accuracies = []\n",
        "precisions_micro = []\n",
        "recalls_micro = []\n",
        "f1_scores_micro = []\n",
        "precisions_macro = []\n",
        "recalls_macro = []\n",
        "f1_scores_macro = []\n",
        "precisions_weighted = []\n",
        "recalls_weighted = []\n",
        "f1_scores_weighted = []\n",
        "\n",
        "epoch = 100\n",
        "\n",
        "for i in range(epoch):\n",
        "  curr_loss = 0.0\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "\n",
        "  for j, data in enumerate(train_loader):\n",
        "    input, output = data[0].to(torch.device('cuda')), data[1].to(torch.device('cuda'))\n",
        "    input = input.reshape(50, -1)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    pred_out = cifarModel.forward(input)\n",
        "    loss = criterion(pred_out, output)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    curr_loss += loss.item()\n",
        "    y_true += output.tolist()\n",
        "    y_pred += torch.argmax(pred_out, dim=1).tolist()\n",
        "\n",
        "  loss_avg = curr_loss / len(train_loader)\n",
        "  losses.append(loss_avg)\n",
        "\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  accuracies.append(acc*100)\n",
        "\n",
        "  precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_true, y_pred, average='micro', zero_division=1)\n",
        "  precisions_micro.append(precision_micro)\n",
        "  recalls_micro.append(recall_micro)\n",
        "  f1_scores_micro.append(f1_micro)\n",
        "\n",
        "  precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=1)\n",
        "  precisions_macro.append(precision_macro)\n",
        "  recalls_macro.append(recall_macro)\n",
        "  f1_scores_macro.append(f1_macro)\n",
        "\n",
        "  precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=1)\n",
        "  precisions_weighted.append(precision_weighted)\n",
        "  recalls_weighted.append(recall_weighted)\n",
        "  f1_scores_weighted.append(f1_weighted)\n",
        "  print(f'epoch: {i:2}  loss: {loss_avg}')\n",
        "\n",
        "\n",
        "\n",
        "perf_metrics = {\n",
        "    'loss': losses,\n",
        "    'accuracy': accuracies,\n",
        "    'precision_micro': precisions_micro,\n",
        "    'recall_micro': recalls_micro,\n",
        "    'f1_micro': f1_scores_micro,\n",
        "    'precision_macro': precisions_macro,\n",
        "    'recall_macro': recalls_macro,\n",
        "    'f1_macro': f1_scores_macro,\n",
        "    'precision_weighted': precisions_weighted,\n",
        "    'recall_weighted': recalls_weighted,\n",
        "    'f1_weighted': f1_scores_weighted\n",
        "}\n",
        "\n",
        "perf_metrics_df = pd.DataFrame(perf_metrics)\n",
        "display(perf_metrics_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q7lxf57_1wyG",
        "outputId": "ddea364b-28eb-4cd5-de2c-4d11bb6a73b2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0  loss: 1.6281588613986968\n",
            "epoch:  1  loss: 1.5376265927553177\n",
            "epoch:  2  loss: 1.4621922241449357\n",
            "epoch:  3  loss: 1.4148250914812088\n",
            "epoch:  4  loss: 1.3877923540472985\n",
            "epoch:  5  loss: 1.3661548935174943\n",
            "epoch:  6  loss: 1.3462309497594833\n",
            "epoch:  7  loss: 1.3322105376124382\n",
            "epoch:  8  loss: 1.3187360795140266\n",
            "epoch:  9  loss: 1.304832927942276\n",
            "epoch: 10  loss: 1.2924062420725821\n",
            "epoch: 11  loss: 1.2832852113842965\n",
            "epoch: 12  loss: 1.2730301996469497\n",
            "epoch: 13  loss: 1.2616254883408546\n",
            "epoch: 14  loss: 1.2525000576376915\n",
            "epoch: 15  loss: 1.2420014393329621\n",
            "epoch: 16  loss: 1.2356184321045875\n",
            "epoch: 17  loss: 1.2256201404333114\n",
            "epoch: 18  loss: 1.2190988965630531\n",
            "epoch: 19  loss: 1.2103671224117278\n",
            "epoch: 20  loss: 1.2015360162258149\n",
            "epoch: 21  loss: 1.1947935062050818\n",
            "epoch: 22  loss: 1.1883573967814445\n",
            "epoch: 23  loss: 1.1780198782682418\n",
            "epoch: 24  loss: 1.1731302959918977\n",
            "epoch: 25  loss: 1.1633190966844558\n",
            "epoch: 26  loss: 1.1581547495126725\n",
            "epoch: 27  loss: 1.150047696352005\n",
            "epoch: 28  loss: 1.1443813976049424\n",
            "epoch: 29  loss: 1.1369230259656906\n",
            "epoch: 30  loss: 1.1285358493328095\n",
            "epoch: 31  loss: 1.1255304497480392\n",
            "epoch: 32  loss: 1.1176697248220444\n",
            "epoch: 33  loss: 1.1111131148338318\n",
            "epoch: 34  loss: 1.1052377632260322\n",
            "epoch: 35  loss: 1.0984693961143495\n",
            "epoch: 36  loss: 1.093615856051445\n",
            "epoch: 37  loss: 1.0871928620934486\n",
            "epoch: 38  loss: 1.080655602991581\n",
            "epoch: 39  loss: 1.0753854268789291\n",
            "epoch: 40  loss: 1.0693084255456924\n",
            "epoch: 41  loss: 1.0647807280421258\n",
            "epoch: 42  loss: 1.0564233195781707\n",
            "epoch: 43  loss: 1.0555348603725434\n",
            "epoch: 44  loss: 1.0480356325507163\n",
            "epoch: 45  loss: 1.0411465571522713\n",
            "epoch: 46  loss: 1.0362925781607628\n",
            "epoch: 47  loss: 1.0309663754105567\n",
            "epoch: 48  loss: 1.0273460471630096\n",
            "epoch: 49  loss: 1.021160586476326\n",
            "epoch: 50  loss: 1.0168774916529655\n",
            "epoch: 51  loss: 1.01314168125391\n",
            "epoch: 52  loss: 1.0064956207871436\n",
            "epoch: 53  loss: 1.0029135174751282\n",
            "epoch: 54  loss: 0.9990317078828812\n",
            "epoch: 55  loss: 0.9943142137527465\n",
            "epoch: 56  loss: 0.9893155920505524\n",
            "epoch: 57  loss: 0.9846589366197586\n",
            "epoch: 58  loss: 0.9812164120674133\n",
            "epoch: 59  loss: 0.9785131955742836\n",
            "epoch: 60  loss: 0.9722145764231682\n",
            "epoch: 61  loss: 0.9677046233415604\n",
            "epoch: 62  loss: 0.9642542371749878\n",
            "epoch: 63  loss: 0.9617458367347718\n",
            "epoch: 64  loss: 0.9617023535370827\n",
            "epoch: 65  loss: 0.9526700053215027\n",
            "epoch: 66  loss: 0.9490010021924973\n",
            "epoch: 67  loss: 0.9483689534068107\n",
            "epoch: 68  loss: 0.9423045577704906\n",
            "epoch: 69  loss: 0.9387622837424279\n",
            "epoch: 70  loss: 0.9383666583299637\n",
            "epoch: 71  loss: 0.9313705695271493\n",
            "epoch: 72  loss: 0.9312148069739342\n",
            "epoch: 73  loss: 0.9284880065917969\n",
            "epoch: 74  loss: 0.9246351300477982\n",
            "epoch: 75  loss: 0.9230104669332504\n",
            "epoch: 76  loss: 0.9171697699129582\n",
            "epoch: 77  loss: 0.9175771477520466\n",
            "epoch: 78  loss: 0.9137798057496548\n",
            "epoch: 79  loss: 0.9110971100926399\n",
            "epoch: 80  loss: 0.908008708357811\n",
            "epoch: 81  loss: 0.9073777350485325\n",
            "epoch: 82  loss: 0.9040220530331134\n",
            "epoch: 83  loss: 0.9027060013413429\n",
            "epoch: 84  loss: 0.9003301439285278\n",
            "epoch: 85  loss: 0.8971364302337169\n",
            "epoch: 86  loss: 0.8949743050932885\n",
            "epoch: 87  loss: 0.8968674267232418\n",
            "epoch: 88  loss: 0.890626722574234\n",
            "epoch: 89  loss: 0.888238155066967\n",
            "epoch: 90  loss: 0.8893560575544834\n",
            "epoch: 91  loss: 0.8864911513030529\n",
            "epoch: 92  loss: 0.8853624618649483\n",
            "epoch: 93  loss: 0.8843997627496719\n",
            "epoch: 94  loss: 0.8826168562471867\n",
            "epoch: 95  loss: 0.8777145727276802\n",
            "epoch: 96  loss: 0.8788647003471851\n",
            "epoch: 97  loss: 0.8817339244484902\n",
            "epoch: 98  loss: 0.875077379822731\n",
            "epoch: 99  loss: 0.8751005528569221\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        loss  accuracy  precision_micro  recall_micro  f1_micro  \\\n",
              "0   1.628159    22.220          0.22220       0.22220   0.22220   \n",
              "1   1.537627    27.568          0.27568       0.27568   0.27568   \n",
              "2   1.462192    32.958          0.32958       0.32958   0.32958   \n",
              "3   1.414825    35.144          0.35144       0.35144   0.35144   \n",
              "4   1.387792    36.286          0.36286       0.36286   0.36286   \n",
              "..       ...       ...              ...           ...       ...   \n",
              "95  0.877715    55.130          0.55130       0.55130   0.55130   \n",
              "96  0.878865    55.108          0.55108       0.55108   0.55108   \n",
              "97  0.881734    54.990          0.54990       0.54990   0.54990   \n",
              "98  0.875077    55.314          0.55314       0.55314   0.55314   \n",
              "99  0.875101    55.162          0.55162       0.55162   0.55162   \n",
              "\n",
              "    precision_macro  recall_macro  f1_macro  precision_weighted  \\\n",
              "0          0.523541       0.22220  0.155068            0.523541   \n",
              "1          0.575130       0.27568  0.200569            0.575130   \n",
              "2          0.615262       0.32958  0.255089            0.615262   \n",
              "3          0.529643       0.35144  0.271927            0.529643   \n",
              "4          0.638435       0.36286  0.281392            0.638435   \n",
              "..              ...           ...       ...                 ...   \n",
              "95         0.846688       0.55130  0.473582            0.846688   \n",
              "96         0.845529       0.55108  0.472840            0.845529   \n",
              "97         0.844044       0.54990  0.471501            0.844044   \n",
              "98         0.848063       0.55314  0.474945            0.848063   \n",
              "99         0.849419       0.55162  0.475071            0.849419   \n",
              "\n",
              "    recall_weighted  f1_weighted  \n",
              "0           0.22220     0.155068  \n",
              "1           0.27568     0.200569  \n",
              "2           0.32958     0.255089  \n",
              "3           0.35144     0.271927  \n",
              "4           0.36286     0.281392  \n",
              "..              ...          ...  \n",
              "95          0.55130     0.473582  \n",
              "96          0.55108     0.472840  \n",
              "97          0.54990     0.471501  \n",
              "98          0.55314     0.474945  \n",
              "99          0.55162     0.475071  \n",
              "\n",
              "[100 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca92b1ef-73a1-4714-8550-d28d2bc2ba87\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision_micro</th>\n",
              "      <th>recall_micro</th>\n",
              "      <th>f1_micro</th>\n",
              "      <th>precision_macro</th>\n",
              "      <th>recall_macro</th>\n",
              "      <th>f1_macro</th>\n",
              "      <th>precision_weighted</th>\n",
              "      <th>recall_weighted</th>\n",
              "      <th>f1_weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.628159</td>\n",
              "      <td>22.220</td>\n",
              "      <td>0.22220</td>\n",
              "      <td>0.22220</td>\n",
              "      <td>0.22220</td>\n",
              "      <td>0.523541</td>\n",
              "      <td>0.22220</td>\n",
              "      <td>0.155068</td>\n",
              "      <td>0.523541</td>\n",
              "      <td>0.22220</td>\n",
              "      <td>0.155068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.537627</td>\n",
              "      <td>27.568</td>\n",
              "      <td>0.27568</td>\n",
              "      <td>0.27568</td>\n",
              "      <td>0.27568</td>\n",
              "      <td>0.575130</td>\n",
              "      <td>0.27568</td>\n",
              "      <td>0.200569</td>\n",
              "      <td>0.575130</td>\n",
              "      <td>0.27568</td>\n",
              "      <td>0.200569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.462192</td>\n",
              "      <td>32.958</td>\n",
              "      <td>0.32958</td>\n",
              "      <td>0.32958</td>\n",
              "      <td>0.32958</td>\n",
              "      <td>0.615262</td>\n",
              "      <td>0.32958</td>\n",
              "      <td>0.255089</td>\n",
              "      <td>0.615262</td>\n",
              "      <td>0.32958</td>\n",
              "      <td>0.255089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.414825</td>\n",
              "      <td>35.144</td>\n",
              "      <td>0.35144</td>\n",
              "      <td>0.35144</td>\n",
              "      <td>0.35144</td>\n",
              "      <td>0.529643</td>\n",
              "      <td>0.35144</td>\n",
              "      <td>0.271927</td>\n",
              "      <td>0.529643</td>\n",
              "      <td>0.35144</td>\n",
              "      <td>0.271927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.387792</td>\n",
              "      <td>36.286</td>\n",
              "      <td>0.36286</td>\n",
              "      <td>0.36286</td>\n",
              "      <td>0.36286</td>\n",
              "      <td>0.638435</td>\n",
              "      <td>0.36286</td>\n",
              "      <td>0.281392</td>\n",
              "      <td>0.638435</td>\n",
              "      <td>0.36286</td>\n",
              "      <td>0.281392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.877715</td>\n",
              "      <td>55.130</td>\n",
              "      <td>0.55130</td>\n",
              "      <td>0.55130</td>\n",
              "      <td>0.55130</td>\n",
              "      <td>0.846688</td>\n",
              "      <td>0.55130</td>\n",
              "      <td>0.473582</td>\n",
              "      <td>0.846688</td>\n",
              "      <td>0.55130</td>\n",
              "      <td>0.473582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.878865</td>\n",
              "      <td>55.108</td>\n",
              "      <td>0.55108</td>\n",
              "      <td>0.55108</td>\n",
              "      <td>0.55108</td>\n",
              "      <td>0.845529</td>\n",
              "      <td>0.55108</td>\n",
              "      <td>0.472840</td>\n",
              "      <td>0.845529</td>\n",
              "      <td>0.55108</td>\n",
              "      <td>0.472840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.881734</td>\n",
              "      <td>54.990</td>\n",
              "      <td>0.54990</td>\n",
              "      <td>0.54990</td>\n",
              "      <td>0.54990</td>\n",
              "      <td>0.844044</td>\n",
              "      <td>0.54990</td>\n",
              "      <td>0.471501</td>\n",
              "      <td>0.844044</td>\n",
              "      <td>0.54990</td>\n",
              "      <td>0.471501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.875077</td>\n",
              "      <td>55.314</td>\n",
              "      <td>0.55314</td>\n",
              "      <td>0.55314</td>\n",
              "      <td>0.55314</td>\n",
              "      <td>0.848063</td>\n",
              "      <td>0.55314</td>\n",
              "      <td>0.474945</td>\n",
              "      <td>0.848063</td>\n",
              "      <td>0.55314</td>\n",
              "      <td>0.474945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.875101</td>\n",
              "      <td>55.162</td>\n",
              "      <td>0.55162</td>\n",
              "      <td>0.55162</td>\n",
              "      <td>0.55162</td>\n",
              "      <td>0.849419</td>\n",
              "      <td>0.55162</td>\n",
              "      <td>0.475071</td>\n",
              "      <td>0.849419</td>\n",
              "      <td>0.55162</td>\n",
              "      <td>0.475071</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca92b1ef-73a1-4714-8550-d28d2bc2ba87')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ca92b1ef-73a1-4714-8550-d28d2bc2ba87 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ca92b1ef-73a1-4714-8550-d28d2bc2ba87');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(epoch), losses, 'b')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "ntwh9xGiUoeQ",
        "outputId": "12cf7742-0dde-4262-beb6-03c4f7abd544"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f641b47dd60>]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAeJUlEQVR4nO3dd5wV9bnH8c+zhWJBwF0FKbKAgJiAZS0oiahRQb2WSGLFaETUxBrzCvHGEqMRcvEa7IYgYqJBrhIb1qtGIQrKoqgoCAhKEQNKgGBswHP/eA6XFdkCe3Znz5zv+/U6r91zZnLmGUe/mf3Nr5i7IyIiua8g6QJERCQ7FOgiIimhQBcRSQkFuohISijQRURSoiipA5eUlHinTp2SOryISE6aPn36x+5eurltiQV6p06dqKioSOrwIiI5ycw+qGqbmlxERFJCgS4ikhIKdBGRlFCgi4ikhAJdRCQlFOgiIimhQBcRSYmcC/S33oLLL4eVK5OuRESkccm5QJ8/H4YPh7lzk65ERKRxyblALyuLnwsWJFuHiEhjo0AXEUmJnAv07beHHXeMphcREdmoxkA3szFmtszMZlazTz8zm2Fmb5vZi9kt8ZvKynSHLiKyqdrcoY8F+le10cxaArcDx7r7HsAPslJZNTp3VqCLiGyqxkB390nAimp2ORX4q7svzOy/LEu1VamsDD74ANatq+8jiYjkjmy0oXcDWpnZC2Y23czOyMJ3VqusDL76Cj78sL6PJCKSO7KxwEURsA9wGNAcmGJmU919zqY7mtkQYAhAx44dt/qAlXu6dOiw1V8jIpIq2bhDXww87e6fuvvHwCSg9+Z2dPdR7l7u7uWlpZtdQalW1HVRROSbshHojwB9zazIzLYB9gdmZeF7q9SxI5gp0EVEKquxycXMxgH9gBIzWwxcDRQDuPud7j7LzJ4C3gTWA6PdvcoujtnQtCm0a6dAFxGprMZAd/dTarHPCGBEViqqpbIyDS4SEaks50aKbqC+6CIiX5ezgV5WFt0Wv/gi6UpERBqHnA509xhgJCIiOR7ooGYXEZENFOgiIimRs4G+yy7QpIkCXURkg5wN9IIC2HVXBbqIyAY5G+igedFFRCrL6UBXX3QRkY1yOtDLyuCTT2D16qQrERFJXs4HOuguXUQEcjzQu3aNn/PmJVuHiEhjkNOB3q1b/Jw9O9k6REQag5wO9G23jRWLFOgiIjke6AA9eijQRUQgRYHunnQlIiLJSkWgr1kDS5cmXYmISLJyPtC7d4+fanYRkXxXY6Cb2RgzW2Zmm10n1Mz6mdkqM5uReV2V/TKr1qNH/FSgi0i+q3FNUWAscCvwp2r2mezux2Sloi20yy6w3XYKdBGRGu/Q3X0SsKIBatkqZnGX/u67SVciIpKsbLWh9zGzN8zsSTPbo6qdzGyImVWYWcXy5cuzdOhoR9cduojku2wE+mvAru7eG7gFeLiqHd19lLuXu3t5aWlpFg4devSAhQvh00+z9pUiIjmnzoHu7qvdfU3m9yeAYjMrqXNlW2DDg9E5cxryqCIijUudA93M2piZZX7fL/Odn9T1e7eEerqIiNSil4uZjQP6ASVmthi4GigGcPc7gYHA+Wa2FvgMONm9Ycdtdu0aD0f1YFRE8lmNge7up9Sw/VaiW2NimjWLudF1hy4i+SznR4puoEm6RCTfpSrQ58yB9euTrkREJBmpCfTu3eGzz2DRoqQrERFJRmoCfUNPl3feSbYOEZGkpCbQ99wTCgvh5ZeTrkREJBmpCfQWLWDvveHFF5OuREQkGakJdICDD4ZXXom2dBGRfJO6QP/yS5g6NelKREQaXqoCvW9fKChQs4uI5KdUBXrLlvFwVIEuIvkoVYEO0ewyZQp8/nnSlYiINKzUBXq/fvDFF/Dqq0lXIiLSsFIX6N/5Tsy8qGYXEck3qQv0Vq2gVy944YWkKxERaVipC3TY2I7+5ZdJVyIi0nBSGej9+sXgomnTkq5ERKThpDLQDz4Yioth/PikKxERaTg1BrqZjTGzZWY2s4b99jWztWY2MHvlbZ3WreHkk+Huu2HVqqSrERFpGLW5Qx8L9K9uBzMrBH4HPJOFmrLiootgzZoIdRGRfFBjoLv7JGBFDbtdCEwAlmWjqGwoL4cDD4RbboF165KuRkSk/tW5Dd3M2gEnAHfUYt8hZlZhZhXLly+v66FrdPHFMH8+PP54vR9KRCRx2XgoOhIY6u41rubp7qPcvdzdy0tLS7Nw6OqdcAK0bw833VTvhxIRSVw2Ar0cuN/M3gcGAreb2fFZ+N46Ky6Gn/4Unn8e3nor6WpEROpXnQPd3cvcvZO7dwIeBH7i7g/X9Xuz5ZxzYJtt4Le/TboSEZH6VZtui+OAKUB3M1tsZmeb2Xlmdl79l1d3O+4IP/tZ9EmvqEi6GhGR+mPunsiBy8vLvaKBEnb1aujSJeZ4efbZmLxLRCQXmdl0dy/f3LZUjhTdVIsWcOWV0Zb+TKPpKS8ikl15EegA550HnTvD0KGwvsb+OCIiuSdvAr1Jk3gw+sYbcN99SVcjIpJ9eRPoAD/8Iey7L/zylzEtgIhImuRVoBcUxFQAH34I112XdDUiItmVV4EOsP/+cOaZcOONMHdu0tWIiGRP3gU6wLBh0KwZXHJJ0pWIiGRPXgZ6mzbw61/DE0/AY48lXY2ISHbkZaADXHghfOtbcNZZMSOjiEiuy9tALy6Ghx6KPun/8R9a2UhEcl/eBjpA164wYQLMmRNL1q1dm3RFIiJbL68DHeCQQ+DWW+Gpp+Cyy5KuRkRk6xUlXUBjcO65MHs2jBwZ0wNcfHHSFYmIbDkFesYNN8AHH8Cll0KnTnDccUlXJCKyZfK+yWWDwkK4917Ybz845RR49dWkKxIR2TIK9Eq22QYefRTatoVjj4WFC5OuSESk9hTom9hpJ5g4ET7/PLoz/utfSVckIlI7tVmCboyZLTOzmVVsP87M3jSzGWZWYWZ9s19mw9p9d3jgAXj7bTj1VFi3LumKRERqVps79LFA/2q2Pwf0dvc9gR8Do+teVvIOPzxmZpw4MbozJrRSn4hIrdXYy8XdJ5lZp2q2V55ZfFsgNdF3/vkx6GjkSCgpgSuuSLoiEZGqZaXbopmdAAwDdgKOrma/IcAQgI4dO2bj0PXuv/8bVqyINUlbtICLLkq6IhGRzcvKQ1F3f8jdewDHA9dWs98ody939/LS0tJsHLreFRTAXXfBCSfEgKMxY5KuSERk87Lay8XdJwGdzawkm9+btKIiGDcOjjgCzj4bfvELzfsiIo1PnQPdzLqamWV+3xtoCnxS1+9tbJo2jT7q558PI0bEQ9N//CPpqkRENqqxDd3MxgH9gBIzWwxcDRQDuPudwInAGWb2FfAZcJJ7OvuENG0Kt98ey9iddx7ssw88/jj07p10ZSIiYEllb3l5uVdUVCRy7Gx4/fUYeLR6dUzBe/jhSVckIvnAzKa7e/nmtmmk6Fbaay+YOjUm8jrqKBg7NumKRCTfKdDroH17mDwZ+vWLpexuvjnpikQknynQ62iHHaIdfUO3xhEjkq5IRPKVAj0LmjSB8ePhpJOiS+N112mqABFpeFrgIkuKi+G++yLcr7wS5s6FO+6IKXlFRBqC7tCzqLAwHo5ecw38+c/Qpw+8917SVYlIvlCgZ1lBAVx1VbSrL1oUfdX/9rekqxKRfKBArycDBsD06dCuHfTvD//zP0lXJCJpp0CvR2Vl8Pe/x8jSk0+Gm25KuiIRSTMFej1r1QqeeSa6NV5yCRx5JMyYkXRVIpJGCvQG0KxZNLn8/vdQUQF77w2DBsHy5UlXJiJpokBvIIWFcYf+3nvRV/2BB+CAA2D27KQrE5G0UKA3sJYtYfhwePFFWLMmQv2555KuSkTSQIGekP33h1deiflg+veHq6+OgBcR2VoK9AR16gQvvQQDB8JvfgPdusVyd+vWJV2ZiOQiBXrCdtghlrd7+eUI+MGD4dBDYcmSpCsTkVyjQG8k+vSJu/WxY2NA0p57wlNPJV2ViOSSGgPdzMaY2TIzm1nF9tPM7E0ze8vMXjYzLci2lczgRz+Kro1t28Zo08sv14LUIlI7tblDHwv0r2b7AuBgd/82cC0wKgt15bUePeKB6ZAh0SNGTTAiUhs1Brq7TwJWVLP9ZXf/Z+btVKB9lmrLa82bwx/+EFPyvvZaNME88ojmWReRqmW7Df1s4Mksf2deO/XUjU0wxx8fXRzfeSfpqkSkMcpaoJvZIUSgD61mnyFmVmFmFcs17r3WevSIB6UjR8Krr0KvXnDBBZo6QES+LiuBbma9gNHAce7+SVX7ufsody939/LS0tJsHDpvFBfHmqVz58K558Kdd0KXLnD99fDvfyddnYg0BnUOdDPrCPwVGOTuc+peklSnpARuuw1mzoyHpb/6Fey1F8yfn3RlIpK02nRbHAdMAbqb2WIzO9vMzjOz8zK7XAXsCNxuZjPMrKIe65WMHj3g4Yfh2Wfh44+jH3uF/smL5DXzhLpNlJeXe4USKCtmz44+68uWwT33wIknRp92EUkfM5vu7uWb26aRoinQowdMmRI/f/AD2H13uPlmWLUq6cpEpCEp0FOiTZuYD+aee2KK3osvhq5dYfLkpCsTkYaiQE+Rpk3hjDNg6tQYadq6NRx2WMwPIyLpp0BPqf32i2A/+GA46yy49FJYUeV4XxFJAwV6irVqBU88AT/5SQxK6tAhfp+jzqUiqaRAT7ni4ui3/sYbcNJJsYBGz55w1VXw1VdJVyci2aRAzxO9esGYMbBwIZx+Olx7bfRdnzUr6cpEJFsU6Hlm553jIemECfD++zHK9MILYdGipCsTkbpSoOep738/pg84/fSYprdLFzjnHPjoo6QrE5GtpUDPY23awOjRMG9eTPj15z/HoKTRozXvukguUqALHTvCLbfAm29C795xp37IIZrwSyTXKNDl/3XrBs8/D3/8I8yYEask3Xtv0lWJSG0p0OVrCgpg8ODo5ti7NwwaBKedFu3taoYRadwU6LJZu+4KL7wQ3RvHj4dvfzva3E8+OaYVEJHGR4EuVSoshCuugAULog/7kUdGk8yBB8LQofD550lXKCKVKdClRh06xHwwf/pT9IgZPBj+679g773hpZeSrk5ENlCgyxZp0SL6rT/1FKxZA337xhzs772XdGUiokCXrXLkkTFtwDXXxARgu+8ec7AvXZp0ZSL5qzZrio4xs2VmNrOK7T3MbIqZfWFmP89+idJYbbttTPI1d27Mw37bbdC5M1xyiUaciiShNnfoY4H+1WxfAVwE3JCNgiT37LJLjC5991045RS49VbYbTcYPlwPTkUaUo2B7u6TiNCuavsyd58GaDLWPNelS/SGmTUrVkq6/HLYYw8YNw6+/DLp6kTSr0Hb0M1siJlVmFnF8uXLG/LQ0oB22w0efhieeQaaNYNTT41+7VddBUuWJF2dSHo1aKC7+yh3L3f38tLS0oY8tCTg8MNjfpjHH4d99oHrrou7+KFDYeXKpKsTSR/1cpF6VVgIRx0FEydGH/aTToIRIyLYR45UU4xINinQpcF07gz33AOvvRZ37JdeGsvhTZigeWJEsqE23RbHAVOA7ma22MzONrPzzOy8zPY2ZrYY+BlwRWafFvVbtuSyPfeM9vUnn4w29oEDY4DSo4/C+vVJVyeSu8wTujUqLy/3ioqKRI4tjcfatdEz5re/jfVOu3WDyy6DM8+EJk2Srk6k8TGz6e5evrltanKRRBUVwZAhMXXAuHExtcC550L37rH26dq1SVcokjsU6NIoFBXF1LyvvhrzxOy4Y0wI1rMn3HgjqJerSM0U6NKomMU8MdOmwUMPQevW0QTTrh388Ifw/vtJVyjSeCnQpVEyg+OPh6lTY7WkCy6IO/feveEvf0m6OpHGSQ9FJWcsWACnnw4vvxzNMwMGRNPMzjvH3OwFuj2RPFDdQ9Gihi5GZGuVlcGLL8L118NvfgP3379x24EHxuLWPXsmV59I0nRPIzmlqCjmhPnnP2Pa3qlT4c47Yfbs6N9+zTXwxRdJVymSDAW65KTtt4euXWH//aOb46xZsXLSr38dC1o/8UTSFYo0PAW6pMJOO8F998HTT0db+tFHwzHHwIwZSVcm0nAU6JIqRxwRMzzecANMmgR77QUHHRRhr6YYSTsFuqROkybRd/3992NQ0rJl0TumUycYNiza30XSSIEuqdW6dczo+O670Ye9Vy/4z/+EDh1g8GB47DH47LOkqxTJHgW6pF5BQYw+ffrpaFMfOBAeeACOPRZKSmIisAULkq5SpO4U6JJXeveOSb+WL4+AHzQIxo+PycAuuACWLk26QpGtp0CXvNSkSTxAvfPOWEnpxz+O3zt0iB4y48erOUZyjwJd8l67dhsHJ/385/DGGzG1wE47xZJ5998Pq1cnXaVIzRToIhldu8Lw4fDBB/Dss3DqqfDCC3DKKXHnPmKEuj5K41abJejGmNkyM5tZxXYzs5vNbJ6ZvWlme2e/TJGGU1gIhx0Gf/gDfPhh9Gf/znfgF7+IuWLGjYN//zvpKkW+qTZ36GOB/tVsHwDslnkNAe6oe1kijUNhYYT5xInxELV587hzLymJ6X3vvhs++STpKkVCjYHu7pOAFdXschzwJw9TgZZm1jZbBYo0FkccEd0en3kGzj4bXn89Hqa2aRPdIu+6C/71r6SrlHyWjTb0dsCiSu8XZz77BjMbYmYVZlaxXGuKSQ4qKoLDD4dbbomRqNOnx4PUefNisFLbtrFG6muvJV2p5KMGfSjq7qPcvdzdy0tLSxvy0CJZZxYLawwbFoE+ZUosk3fvvbDPPtCnT6yu9OWXSVcq+SIbgb4E6FDpffvMZyJ5wwwOOADGjIkHqSNHwscfw2mnwa67whVXaD1UqX/ZCPRHgTMyvV0OAFa5u8bbSd5q2RIuvjjmkHniibiLv/566Nw52trHjIGPPkq6SkmjGpegM7NxQD+gxMwWA1cDxQDufifwBHAUMA/4N3BWfRUrkksKCmLd0wEDYOHCCPK7744HqhDNMoceGtP7HnggqBVS6kqLRIs0IHd46y14/PF4TZu2sY19wIBoj+/dO9kapXGrbpFojRQVaUBmMY3v5ZfD3/8Oq1bB5MmxdN7UqbEgx6BB0VwjsqUU6CIJatYM+vaFq6+G+fNh6FCYMAF69IgBTXffrb7tUnsKdJFGomXLaHKZPx9+97tYaenHP45RqUccATfdFIthr1+fdKXSWKkNXaSRco++7Q89FO3ts2bF5zvsAPvuG5OJFRREM063bvCTn8TAJ0m36trQFegiOWL+/Jgo7JVX4rVoUYT++vWxTuqhh8bEYTvtlHSlUp+qC3T9/7lIjujcOV5nnvnNbWPHwvnnx0PVv/wFvvvduHOX/KI2dJEUOPPMaJ5p3hz69YuHqkOHwvPPRzfJ99+HNWsSLlLqnQJdJCX23DMmBbvtNujUCW68MeZ179ULysqgVauYOGzRopq+SXKV2tBFUmrlyhi4tHp1vKZNg9Gj40HqkCFwxhkxLUGBbutyih6KiggQy+tde220ua9bF9P99u8fc7o3bw7bbx8zRu6yS9KVSlUU6CLyNR9/DE8+CY89Bs89F3fwa9fGtu22i5GrF10ExcWJlimboUAXkRqtXRtdIy+7LJbc2333GMVaWBj927t3j4nEevWKzyQZ6rYoIjUqKooBSo89FoF+5ZXx+7p1MYHYqlWx3/bbw/e+BwMHwjHHQIsWydYtGynQReQbjjkmXpUtXBgTik2aFEH/0EPQtGk8WO3aFbp0gUMOiTlo1Ac+GWpyEZEttn599HufMCEWy37vvY3dIb/73WiD79dPwV4f1OQiIllVUBDt6QcdtPGzTz+N2SGHDYtpCEpL4auv4LPPog/88cfDiSfCwQfrYWt90R26iGTV55/H6kyvvx5dIZs3hwULYjm+Tz+NNvc+fWKVpr5942ezZklXnTvqfIduZv2Bm4BCYLS7D99k+67AGKAUWAGc7u6L61S1iOSkZs1i5sdNffYZPP10vF56KZpl3GP/gw6KcC8picAvKYnPdtihwcvPaTXeoZtZITAHOBxYDEwDTnH3dyrt8wAw0d3vMbNDgbPcfVB136s7dJH8tnJlBPtzz8XrzTe/vr2oKO7ejzwyet906BCvtm3zu22+Tv3QzawP8Gt3PzLz/nIAdx9WaZ+3gf7uvsjMDFjl7tV2ZlKgi0hlX3yxcZqCRYvgmWdi8NOMGV/fr6QEysvj1a9f3MnnU5NNXQN9IBHWgzPvBwH7u/sFlfb5C/CKu99kZt8HJgAl7v7JJt81BBgC0LFjx30++OCDOpyWiOSDlStjyoJFi2LWyNdfh4oKePvt6CPfvHn0rDnggJigrFevmFly1iyYPRu+/W044YT03NU3RC+XnwO3mtmZwCRgCbBu053cfRQwCuIOPUvHFpEUa9kyXr17f/3zNWvgxRfjTv7ZZ+NnVfen5eUwfHjMPplmtQn0JUCHSu/bZz77f+7+IfB9ADPbDjjR3VdmqUYRkW/Ybjs4+uh4QfSgmTkz5n/ffvuYuqBLF3jwQbjqqhjd2rMn7LdfBHxJCXz0UbyaNIkBUX36wLbbJntedVGbJpci4qHoYUSQTwNOdfe3K+1TAqxw9/Vm9ltgnbtfVd33qg1dRBrK55/DH/8ITz0V0wgvX75xW3FxNN2sXx8PYvfYI2abbNs2ZqEsLY1Xmzaw227Qvn2yUw7XqcnF3dea2QXA00S3xTHu/raZ/QaocPdHgX7AMDNzosnlp1mrXkSkjpo1gwsvjJd7tMevXh2h3bp1NN+8/HI04bzxRty1z5gBy5ZF2Fe2zTYR+mecEa9N57L5xz9g8uT43x97bPxF0FA0sEhEpArr18dD2eXLYckSmDMnXpMnx4PZ7baL0a/r18PSpfHwdu7cr3/H6afH6Nn27bNTk6bPFRHJsmnTYrm/Rx6JAVBt20ZTzX77xfQG3brBDTfEUoBmsSzgBoMHxzTFW0NzuYiIZNm++8bKT9W5/no45xwYMSIWFYEI9zZt6qcmBbqISD0qK4Pbb2+YY2l5WBGRlFCgi4ikhAJdRCQlFOgiIimhQBcRSQkFuohISijQRURSQoEuIpISiQ39N7PlwNaucFECfJzFcnJFPp53Pp4z5Od55+M5w5af967uXrq5DYkFel2YWUVVcxmkWT6edz6eM+TneefjOUN2z1tNLiIiKaFAFxFJiVwN9FFJF5CQfDzvfDxnyM/zzsdzhiyed062oYuIyDfl6h26iIhsQoEuIpISORfoZtbfzN41s3lm9suk66kPZtbBzP5mZu+Y2dtmdnHm89Zm9r9mNjfzs1XStdYHMys0s9fNbGLmfZmZvZK55uPNrEnSNWaTmbU0swfNbLaZzTKzPvlwrc3s0sy/3zPNbJyZNUvjtTazMWa2zMxmVvpss9fXws2Z83/TzPbekmPlVKCbWSFwGzAA6AmcYmY9k62qXqwFLnP3nsABwE8z5/lL4Dl33w14LvM+jS4GZlV6/zvg9+7eFfgncHYiVdWfm4Cn3L0H0Js491RfazNrB1wElLv7t4BC4GTSea3HAv03+ayq6zsA2C3zGgLcsSUHyqlAB/YD5rn7fHf/ErgfOC7hmrLO3Ze6+2uZ3/9F/AfejjjXezK73QMcn0iB9cjM2gNHA6Mz7w04FHgws0uqztvMdgC+C9wF4O5fuvtK8uBaE0tgNjezImAbYCkpvNbuPglYscnHVV3f44A/eZgKtDSztrU9Vq4FejtgUaX3izOfpZaZdQL2Al4Bdnb3pZlNHwE7J1VXPRoJ/AJYn3m/I7DS3ddm3qftmpcBy4G7M81Mo81sW1J+rd19CXADsJAI8lXAdNJ9rSur6vrWKeNyLdDzipltB0wALnH31ZW3efQ3TVWfUzM7Bljm7tOTrqUBFQF7A3e4+17Ap2zSvJLSa92KuBstA3YBtuWbzRJ5IZvXN9cCfQnQodL79pnPUsfMiokwv8/d/5r5+B8b/vzK/FyWVH315CDgWDN7n2hOO5RoX26Z+bMc0nfNFwOL3f2VzPsHiYBP+7X+HrDA3Ze7+1fAX4nrn+ZrXVlV17dOGZdrgT4N2C3zJLwJ8RDl0YRryrpMu/FdwCx3v7HSpkeBH2V+/xHwSEPXVp/c/XJ3b+/unYhr+7y7nwb8DRiY2S1V5+3uHwGLzKx75qPDgHdI+bUmmloOMLNtMv++bzjv1F7rTVR1fR8Fzsj0djkAWFWpaaZm7p5TL+AoYA7wHvCrpOupp3PsS/wJ9iYwI/M6imhPfg6YCzwLtE661nr8Z9APmJj5vTPwKjAPeABomnR9WT7XPYGKzPV+GGiVD9cauAaYDcwE/gw0TeO1BsYRzwm+Iv4iO7uq6wsY0ZPvPeAtohdQrY+lof8iIimRa00uIiJSBQW6iEhKKNBFRFJCgS4ikhIKdBGRlFCgi4ikhAJdRCQl/g+QoxOidfc/IwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(epoch), accuracies, 'b')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Dw6dm1h-2Rkp",
        "outputId": "382b1886-9ba0-4016-b21a-756012fae079"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f636dd8dca0>]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "target_out = []\n",
        "pred_out = []\n",
        "with torch.no_grad():\n",
        "    for (i, data) in enumerate(test_loader):\n",
        "        images, labels = data[0].to(torch.device('cuda')), data[1].to(torch.device('cuda'))\n",
        "        # Predict the class of the image\n",
        "        images = images.reshape(100, -1)\n",
        "        outputs = cifarModel.forward(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        pred_out += predicted.tolist()\n",
        "        target_out += labels.tolist()\n",
        "\n",
        "\n",
        "loss_avg = curr_loss / len(train_loader)\n",
        "\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_true, y_pred, average='micro', zero_division=1)\n",
        "\n",
        "\n",
        "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=1)\n",
        "\n",
        "\n",
        "precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=1)\n",
        "\n",
        "\n",
        "perf_metrics = {\n",
        "    'loss': [loss_avg],\n",
        "    'accuracy': [acc*100],\n",
        "    'precision_micro': [precision_micro*100],\n",
        "    'recall_micro': [recall_micro*100],\n",
        "    'f1_micro': [f1_micro*100],\n",
        "    'precision_macro': [precision_macro*100],\n",
        "    'recall_macro': [recall_macro*100],\n",
        "    'f1_macro': [f1_macro*100],\n",
        "    'precision_weighted': [precision_weighted*100],\n",
        "    'recall_weighted': [recall_weighted*100],\n",
        "    'f1_weighted': [f1_weighted*100]\n",
        "}\n",
        "\n",
        "perf_metrics_df = pd.DataFrame(perf_metrics)\n",
        "display(perf_metrics_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "1tMryjsyQWE2",
        "outputId": "744ab0e4-928b-48f1-b554-4c0f9eeff340"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       loss  accuracy  precision_micro  recall_micro  f1_micro  \\\n",
              "0  0.875101    55.162           55.162        55.162    55.162   \n",
              "\n",
              "   precision_macro  recall_macro   f1_macro  precision_weighted  \\\n",
              "0        84.941871        55.162  47.507079           84.941871   \n",
              "\n",
              "   recall_weighted  f1_weighted  \n",
              "0           55.162    47.507079  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16eff766-32be-48f5-8a91-b72189acf896\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision_micro</th>\n",
              "      <th>recall_micro</th>\n",
              "      <th>f1_micro</th>\n",
              "      <th>precision_macro</th>\n",
              "      <th>recall_macro</th>\n",
              "      <th>f1_macro</th>\n",
              "      <th>precision_weighted</th>\n",
              "      <th>recall_weighted</th>\n",
              "      <th>f1_weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.875101</td>\n",
              "      <td>55.162</td>\n",
              "      <td>55.162</td>\n",
              "      <td>55.162</td>\n",
              "      <td>55.162</td>\n",
              "      <td>84.941871</td>\n",
              "      <td>55.162</td>\n",
              "      <td>47.507079</td>\n",
              "      <td>84.941871</td>\n",
              "      <td>55.162</td>\n",
              "      <td>47.507079</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16eff766-32be-48f5-8a91-b72189acf896')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16eff766-32be-48f5-8a91-b72189acf896 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16eff766-32be-48f5-8a91-b72189acf896');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XvhCEt8ScyBS"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}